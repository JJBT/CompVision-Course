{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"DenseNet.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"gt9LyU4cGL93","colab_type":"code","colab":{}},"source":["from google.colab import drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zxmsmEDIGQL2","colab_type":"code","outputId":"80ca678a-26f9-4f5f-e7e1-e2805bcbe99a","executionInfo":{"status":"ok","timestamp":1567968411144,"user_tz":-180,"elapsed":27105,"user":{"displayName":"Владимир Чернявский","photoUrl":"","userId":"13952990532110748403"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["drive.mount('/content/gdrive')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cUeBq6DCK1Im","colab_type":"code","outputId":"c2ff5762-0e55-4d06-f582-3bfe86bbfa2b","executionInfo":{"status":"ok","timestamp":1567968416814,"user_tz":-180,"elapsed":1711,"user":{"displayName":"Владимир Чернявский","photoUrl":"","userId":"13952990532110748403"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd 'gdrive/My Drive/Colab Notebooks/CompVision-Course/Kaggle'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/CompVision-Course/Kaggle\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"aP9NWDaRFYM6","colab_type":"code","colab":{}},"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","import os\n","\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hzqt68-lMeH5","colab_type":"code","colab":{}},"source":["\n","import torch\n","import random\n","\n","random.seed(8)\n","np.random.seed(8)\n","torch.manual_seed(8)\n","torch.cuda.manual_seed(8)\n","torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"6ZnWWiVtFYNF","colab_type":"code","outputId":"6e8c22b5-db00-4682-cd87-ed94ff66b0bc","executionInfo":{"status":"ok","timestamp":1567968432676,"user_tz":-180,"elapsed":1066,"user":{"displayName":"Владимир Чернявский","photoUrl":"","userId":"13952990532110748403"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data_root = 'plates/plates/'\n","print(os.listdir(data_root))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['.DS_Store', 'test', 'train']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"wlkb0VyFFYNM","colab_type":"code","outputId":"05738d44-35a5-4f89-9d8c-c9106aad69e7","executionInfo":{"status":"ok","timestamp":1567968487347,"user_tz":-180,"elapsed":35787,"user":{"displayName":"Владимир Чернявский","photoUrl":"","userId":"13952990532110748403"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["import shutil \n","from tqdm import tqdm\n","\n","train_dir = 'train'\n","val_dir = 'val'\n","\n","class_names = ['cleaned', 'dirty']\n","\n","# Создаем папки для тренировки и валидации\n","for class_name in class_names:\n","    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n","        \n","for class_name in class_names:\n","    source_dir = os.path.join(data_root, 'train', class_name)\n","    for i, filename in enumerate(tqdm(os.listdir(source_dir))):\n","        dest_dir = os.path.join(train_dir, class_name)\n","        shutil.copy(os.path.join(source_dir, filename), os.path.join(dest_dir, filename))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 21/21 [00:16<00:00,  1.29it/s]\n","100%|██████████| 21/21 [00:17<00:00,  1.32it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"LykAUxdpy035","colab_type":"code","colab":{}},"source":["import random\n","from PIL import ImageOps\n","import torchvision.transforms.functional as F\n","\n","def my_inverse_transformation(img, p=0.5):\n","    if not F._is_pil_image(img):\n","        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n","    if random.random() > p:\n","        return ImageOps.invert(img)\n","    else:\n","        return img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKdFtzA5dVIE","colab_type":"code","colab":{}},"source":["import cv2\n","from PIL import Image\n","from torchvision.transforms.functional import _is_pil_image\n","from torchvision import transforms, models\n","\n","\n","class Segmentate:\n","    center_crop = transforms.CenterCrop(224)\n","    initThresh = 105\n","\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, img):\n","        if not _is_pil_image(img):\n","            raise TypeError('Img should be PIL Image. Got {}'.format(type(img)))\n","\n","        cimg = img.copy()\n","        img = np.array(img)\n","\n","        # Convert to gray-scale\n","        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","\n","        p1 = self.initThresh\n","        p2 = self.initThresh * 0.4\n","\n","        # Detect circles using HoughCircles transform\n","        circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 500, param1=p1, param2=p2, minRadius=10,\n","                                   maxRadius=170)\n","\n","        t = 400\n","        if circles is None:\n","            return self.center_crop(cimg)\n","\n","        c = np.uint16(np.around(circles))[0, 0]\n","\n","        # Draw the outer circle\n","        cv2.circle(img, (c[0], c[1]), c[2] + t // 2 - 15, (0, 0, 0), t)\n","\n","        thr = -10\n","        # Centering ad cropping\n","        try:\n","            img = img[c[1] - c[2] - thr:c[1] + c[2] + thr, c[0] - c[2] - thr:c[0] + c[2] + thr]\n","            pil_img = Image.fromarray(img)\n","        except ValueError:\n","            return cimg\n","\n","        return pil_img\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vIEmKaeAuUBn","colab_type":"code","colab":{}},"source":["class ChangeContrast:\n","    def __init__(self, level):\n","        self.level = level\n","        \n","    def __call__(self, img):\n","        self.factor_ = (259 * (self.level + 255)) / (255 * (259 - self.level))\n","        def contrast(c):\n","            return 128 + self.factor_ * (c - 128)\n","        return img.point(contrast)\n","    \n","    def __repr__(self):\n","        return self.__class__.__name__ + '(contrast_level={})'.format(self.level)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"5JZ0sB10FYNS","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","import time\n","import copy\n","import PIL\n","\n","shift_const = [0.485, 0.456, 0.406]\n","scale_const = [0.229, 0.224, 0.225]\n","\n","train_transforms = transforms.Compose([\n","    transforms.Pad(50, padding_mode='edge'),\n","    transforms.RandomRotation((0, 360), expand=True),\n","    transforms.CenterCrop(224),    \n","#     ChangeContrast(70),\n","#     Segmentate(),\n","#     transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","#     transforms.ColorJitter(0.5, 0.6, 0.4, 0.25),\n","#     transforms.Lambda(lambda x: my_inverse_transformation(x, 0.3)),\n","    transforms.ToTensor(),\n","#     transforms.Lambda(lambda x: x[np.random.permutation(3), :, :]),\n","    transforms.Normalize(shift_const, scale_const)\n","])\n","\n","val_transforms = transforms.Compose([\n","    transforms.CenterCrop(224),\n","#     ChangeContrast(70),\n","#     Segmentate(),\n","#     transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(shift_const, scale_const)\n","])\n","\n","train_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\n","val_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n","\n","batch_size = 20\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\n","val_loader = torch.utils.data.DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"iF5Ar1deFYNZ","colab_type":"code","outputId":"ee8ace11-4f08-4add-e670-7cc3967250d4","executionInfo":{"status":"ok","timestamp":1567901476445,"user_tz":-180,"elapsed":1486,"user":{"displayName":"Владимир Чернявский","photoUrl":"","userId":"13952990532110748403"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(len(train_loader), len(train_dataset))\n","print(len(val_loader), len(val_dataset))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2 40\n","38 744\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a0GsdfC5mAq4","colab_type":"code","outputId":"1fb6af8c-b109-4edc-e020-898cb71ee4af","executionInfo":{"status":"ok","timestamp":1567901503524,"user_tz":-180,"elapsed":27255,"user":{"displayName":"Владимир Чернявский","photoUrl":"","userId":"13952990532110748403"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["!pip install pretrainedmodels"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pretrainedmodels in /usr/local/lib/python3.6/dist-packages (0.7.4)\n","Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (2.3.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.1.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.3.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.28.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch->pretrainedmodels) (1.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (1.16.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (4.3.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->pretrainedmodels) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UiJ4LdqzfNE9","colab_type":"code","colab":{}},"source":["def make_pnasnet():\n","    import pretrainedmodels\n","    model = pretrainedmodels.pnasnet5large(num_classes=1000)\n","    model.last_linear = torch.nn.Linear(model.last_linear.in_features, 2)\n","\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","    return model\n","\n","\n","def make_xception():\n","    import pretrainedmodels\n","    model = pretrainedmodels.xception()\n","    model.last_linear = torch.nn.Linear(model.last_linear.in_features, 2)\n","\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","    return model\n","\n","\n","def make_resnext():\n","    import pretrainedmodels\n","    model = pretrainedmodels.se_resnext50_32x4d()\n","    model.last_linear = torch.nn.Linear(model.last_linear.in_features, 2)\n","\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","    return model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NC7XSyRdfQFd","colab_type":"code","colab":{}},"source":["def make_densenet(freeze=False):\n","    import pretrainedmodels\n","    model = pretrainedmodels.densenet121()\n","#     filename = 'models/inceptionresnetv2.pth'\n","#     model = torch.load_state_dict(filename)\n","    if freeze:\n","        for param in model.parameters():\n","            param.requires_grad = False\n","    \n","    model.last_linear = torch.nn.Linear(model.last_linear.in_features, 2)\n","    \n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KaLQwKtVbteO","colab_type":"code","colab":{}},"source":["def make_inception_resnet_v2(freeze=False):\n","    import pretrainedmodels\n","    model = pretrainedmodels.inceptionresnetv2()\n","#     filename = 'models/inceptionresnetv2.pth'\n","#     model = torch.load_state_dict(filename)\n","    if freeze:\n","        for param in model.parameters():\n","            param.requires_grad = False\n","    \n","    model.last_linear = torch.nn.Linear(model.last_linear.in_features, 2)\n","    \n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wuLApmtfbUuY","colab_type":"code","colab":{}},"source":["def make_vgg():\n","    model = models.vgg19_bn(pretrained=True)\n","    child_counter = 0\n","    for child in model.features.children():\n","        if child_counter < 48:\n","            for param in child.parameters():\n","                param.requires_grad = False\n","        child_counter += 1\n","        \n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QJLLpScvq-3P","colab_type":"code","colab":{}},"source":["def make_resnet():\n","    model = models.resnet18(pretrained=True)\n","#     for param in model.parameters():\n","#         param.requires_grad = False\n","\n","#     child_counter = 0\n","#     for child in model.children():\n","#         if child_counter == 7:\n","#             child_of_child_counter = 0\n","#             for child_of_child in child.children():\n","#                 if child_of_child_counter == 1:\n","#                     for param in child_of_child.parameters():\n","#                         param.requires_grad = True\n","#                 child_of_child_counter += 1\n","#         child_counter += 1\n","        \n","    model.fc = torch.nn.Linear(model.fc.in_features,2)\n","\n","\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xm64GqIZhTJf","colab_type":"code","colab":{}},"source":["from torchvision import models\n","from itertools import product\n","\n","class GridSearch():\n","    def __init__(self, loss, optimizer=torch.optim.SGD, optimizer_params={}, scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={}):\n","        \"\"\"\n","        [object]_params : dict\n","            Must include values wrapped in a list for all default parameters of [object] \n","            ----\n","            Example:\n","                scheduler_params={'step_size': [7], 'gamma': [0.1, 0.01, 0.001]}\n","        \"\"\"\n","        self.loss = loss\n","        self.optimizer = optimizer\n","        self.optimizer_params = optimizer_params\n","        self.scheduler = scheduler\n","        self.scheduler_params = scheduler_params\n","        self.best_model = ...\n","        self.best_acc = 0\n","        \n","    def tune(self):\n","        \n","        self.param_grid_ = list(product(*{**self.optimizer_params, **self.scheduler_params}.values()))\n","        self.param_grid_score_ = {}\n","        \n","        self.param_grid_len_ = len(self.param_grid_)\n","        for (i, param_set) in enumerate(self.param_grid_):\n","            print('Parameters set {}/{}'.format(i, self.param_grid_len_), end='\\n')\n","            print(param_set)\n","\n","            self.model_ = make_densenet()\n","            \n","            if self.optimizer == torch.optim.SGD:\n","                self.optimizer_ = self.optimizer(self.model_.parameters(), *param_set[:len(self.optimizer_params)])\n","            elif self.optimizer == torch.optim.Adam:\n","                self.optimizer_ = self.optimizer(self.model_.parameters(), *param_set[:len(self.optimizer_params)])\n","            else:\n","                raise RuntimeError('unknown type of optimizer')\n","                \n","            self.scheduler_ = self.scheduler(self.optimizer_, *param_set[len(self.optimizer_params):])\n","\n","            _, best_model, score = train_model(self.model_, self.loss, self.optimizer_, self.scheduler_, n_epochs=26)\n","            if score > self.best_acc:\n","                self.best_model = copy.deepcopy(best_model)\n","                self.best_acc = score\n","            else:\n","                del best_model\n","#             self.current_score_ = sum(score[-3:]) / 3\n","            \n","#             self.param_grid_score_[str(param_set)[1:-1]] = self.current_score_\n","#         self.best_score_ = max(self.param_grid_score_.values())\n","#         self.best_params_ = max(self.param_grid_score_, key=lambda key: self.param_grid_score_[key])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S8j4IF1sRsWZ","colab_type":"code","colab":{}},"source":["import copy\n","def train_model(model, loss, optimizer, scheduler, n_epochs):\n","    best_acc = 0\n","    validation_accuracy = []\n","    \n","    for epoch in range(n_epochs):\n","        print('Epoch {}:'.format(epoch))\n","        \n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                dataloader = train_loader\n","#                 scheduler.step()\n","                model.train()\n","            else:\n","                dataloader = val_loader\n","                model.eval()\n","                \n","            batch_loss = 0.\n","            batch_acc = 0.\n","            \n","            for inputs, labels in dataloader:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                \n","                optimizer.zero_grad()\n","                \n","                with torch.set_grad_enabled(phase == 'train'):\n","                    preds = model(inputs)\n","                    loss_val = loss(preds, labels)\n","                    preds_class = preds.argmax(dim=1)\n","                    \n","                    if phase == 'train':\n","                        loss_val.backward()\n","                        optimizer.step()\n","                        scheduler.step()\n","                        \n","                batch_loss += loss_val.item()\n","                batch_acc += (preds_class == labels.data).float().mean().item()\n","                \n","            epoch_loss = batch_loss / len(dataloader)\n","            epoch_acc = batch_acc / len(dataloader)\n","            \n","            if phase == 'val':\n","                validation_accuracy.append(epoch_acc)\n","                if epoch_acc > best_acc:\n","                    best_model = copy.deepcopy(model)\n","                    best_acc = epoch_acc\n","        \n","            print('{} Loss: {:.3f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","            \n","    return model, best_model, best_acc    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5srnOvnSALsB","colab_type":"code","colab":{}},"source":["# child_counter = 0\n","# for child in model.children():\n","#     print('child {} is'.format(child_counter))\n","#     print(child)\n","#     child_counter += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HpU7cyly91RW","colab_type":"code","colab":{}},"source":["# child_counter = 0\n","# child_of_child_counter = 0\n","\n","# for child in model.children():\n","#     for child_child in child.children():\n","#         print('child {} of child {} is '.format(child_of_child_counter, child_counter))\n","#         print(child_child)\n","#         child_of_child_counter += 1\n","#     child_of_child_counter = 0\n","#     child_counter += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yo74nmdF3OoH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3lyuoYt8OCd","colab_type":"code","colab":{}},"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cpdp2Tu8F9um","colab_type":"code","colab":{}},"source":["loss = torch.nn.CrossEntropyLoss()\n","optimizer_params={'lr': [0.01, 0.1],\n","                  'momentum': [0.9, 0],\n","                  'dampening': [0.01],\n","                  'weight_decay': [0.1, 0.0001, 1],\n","                  'nesterov': [False]\n","                 }\n","scheduler_params = {'T_max': [5, 15]}\n","\n","model_cv = GridSearch(loss, optimizer=torch.optim.SGD, optimizer_params=optimizer_params,\n","                     scheduler=torch.optim.lr_scheduler.CosineAnnealingLR, scheduler_params=scheduler_params)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zTXJCWB43bLO","colab_type":"code","outputId":"5de212dc-89ed-4dcb-9608-611e2754d8a5","executionInfo":{"status":"ok","timestamp":1567908792459,"user_tz":-180,"elapsed":3437486,"user":{"displayName":"Владимир Чернявский","photoUrl":"","userId":"13952990532110748403"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model_cv.tune()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Parameters set 0/24\n","(0.01, 0.9, 0.01, 0.1, False, 5)\n","Epoch 0:\n","train Loss: 0.613 Acc: 0.6250\n","val Loss: 0.432 Acc: 0.7868\n","Epoch 1:\n","train Loss: 0.406 Acc: 0.8250\n","val Loss: 0.317 Acc: 0.9500\n","Epoch 2:\n","train Loss: 0.240 Acc: 0.9750\n","val Loss: 0.313 Acc: 0.9461\n","Epoch 3:\n","train Loss: 0.216 Acc: 1.0000\n","val Loss: 0.277 Acc: 0.9461\n","Epoch 4:\n","train Loss: 0.141 Acc: 1.0000\n","val Loss: 0.176 Acc: 0.9553\n","Epoch 5:\n","train Loss: 0.038 Acc: 1.0000\n","val Loss: 0.126 Acc: 0.9566\n","Epoch 6:\n","train Loss: 0.015 Acc: 1.0000\n","val Loss: 0.118 Acc: 0.9539\n","Epoch 7:\n","train Loss: 0.006 Acc: 1.0000\n","val Loss: 0.112 Acc: 0.9553\n","Epoch 8:\n","train Loss: 0.008 Acc: 1.0000\n","val Loss: 0.114 Acc: 0.9579\n","Epoch 9:\n","train Loss: 0.007 Acc: 1.0000\n","val Loss: 0.129 Acc: 0.9474\n","Epoch 10:\n","train Loss: 0.003 Acc: 1.0000\n","val Loss: 0.128 Acc: 0.9592\n","Epoch 11:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.134 Acc: 0.9566\n","Epoch 12:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.119 Acc: 0.9566\n","Epoch 13:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.116 Acc: 0.9579\n","Epoch 14:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.130 Acc: 0.9526\n","Epoch 15:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.165 Acc: 0.9474\n","Epoch 16:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.167 Acc: 0.9487\n","Epoch 17:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.139 Acc: 0.9474\n","Epoch 18:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.127 Acc: 0.9539\n","Epoch 19:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.150 Acc: 0.9513\n","Epoch 20:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.204 Acc: 0.9474\n","Epoch 21:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.202 Acc: 0.9474\n","Epoch 22:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.153 Acc: 0.9500\n","Epoch 23:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.136 Acc: 0.9553\n","Epoch 24:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.168 Acc: 0.9474\n","Epoch 25:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.238 Acc: 0.9421\n","Parameters set 1/24\n","(0.01, 0.9, 0.01, 0.1, False, 15)\n","Epoch 0:\n","train Loss: 0.673 Acc: 0.5750\n","val Loss: 0.468 Acc: 0.9039\n","Epoch 1:\n","train Loss: 0.349 Acc: 0.9250\n","val Loss: 0.270 Acc: 0.9316\n","Epoch 2:\n","train Loss: 0.135 Acc: 1.0000\n","val Loss: 0.245 Acc: 0.9158\n","Epoch 3:\n","train Loss: 0.057 Acc: 1.0000\n","val Loss: 0.196 Acc: 0.9276\n","Epoch 4:\n","train Loss: 0.019 Acc: 1.0000\n","val Loss: 0.173 Acc: 0.9329\n","Epoch 5:\n","train Loss: 0.020 Acc: 1.0000\n","val Loss: 0.156 Acc: 0.9447\n","Epoch 6:\n","train Loss: 0.011 Acc: 1.0000\n","val Loss: 0.147 Acc: 0.9500\n","Epoch 7:\n","train Loss: 0.011 Acc: 1.0000\n","val Loss: 0.136 Acc: 0.9553\n","Epoch 8:\n","train Loss: 0.016 Acc: 1.0000\n","val Loss: 0.132 Acc: 0.9579\n","Epoch 9:\n","train Loss: 0.013 Acc: 1.0000\n","val Loss: 0.127 Acc: 0.9579\n","Epoch 10:\n","train Loss: 0.023 Acc: 1.0000\n","val Loss: 0.124 Acc: 0.9618\n","Epoch 11:\n","train Loss: 0.011 Acc: 1.0000\n","val Loss: 0.119 Acc: 0.9605\n","Epoch 12:\n","train Loss: 0.012 Acc: 1.0000\n","val Loss: 0.120 Acc: 0.9566\n","Epoch 13:\n","train Loss: 0.018 Acc: 1.0000\n","val Loss: 0.133 Acc: 0.9539\n","Epoch 14:\n","train Loss: 0.004 Acc: 1.0000\n","val Loss: 0.159 Acc: 0.9539\n","Epoch 15:\n","train Loss: 0.003 Acc: 1.0000\n","val Loss: 0.216 Acc: 0.9461\n","Epoch 16:\n","train Loss: 0.005 Acc: 1.0000\n","val Loss: 0.275 Acc: 0.9408\n","Epoch 17:\n","train Loss: 0.012 Acc: 1.0000\n","val Loss: 0.317 Acc: 0.9382\n","Epoch 18:\n","train Loss: 0.005 Acc: 1.0000\n","val Loss: 0.314 Acc: 0.9382\n","Epoch 19:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.270 Acc: 0.9408\n","Epoch 20:\n","train Loss: 0.003 Acc: 1.0000\n","val Loss: 0.206 Acc: 0.9513\n","Epoch 21:\n","train Loss: 0.005 Acc: 1.0000\n","val Loss: 0.153 Acc: 0.9579\n","Epoch 22:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.122 Acc: 0.9579\n","Epoch 23:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.111 Acc: 0.9632\n","Epoch 24:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.107 Acc: 0.9658\n","Epoch 25:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.107 Acc: 0.9645\n","Parameters set 2/24\n","(0.01, 0.9, 0.01, 0.0001, False, 5)\n","Epoch 0:\n","train Loss: 0.739 Acc: 0.5250\n","val Loss: 0.539 Acc: 0.7868\n","Epoch 1:\n","train Loss: 0.360 Acc: 0.9250\n","val Loss: 0.389 Acc: 0.9066\n","Epoch 2:\n","train Loss: 0.296 Acc: 0.9000\n","val Loss: 0.361 Acc: 0.9105\n","Epoch 3:\n","train Loss: 0.224 Acc: 0.9750\n","val Loss: 0.292 Acc: 0.9289\n","Epoch 4:\n","train Loss: 0.114 Acc: 1.0000\n","val Loss: 0.164 Acc: 0.9474\n","Epoch 5:\n","train Loss: 0.030 Acc: 1.0000\n","val Loss: 0.126 Acc: 0.9566\n","Epoch 6:\n","train Loss: 0.025 Acc: 1.0000\n","val Loss: 0.123 Acc: 0.9592\n","Epoch 7:\n","train Loss: 0.007 Acc: 1.0000\n","val Loss: 0.120 Acc: 0.9579\n","Epoch 8:\n","train Loss: 0.005 Acc: 1.0000\n","val Loss: 0.118 Acc: 0.9632\n","Epoch 9:\n","train Loss: 0.060 Acc: 0.9750\n","val Loss: 0.120 Acc: 0.9618\n","Epoch 10:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.142 Acc: 0.9566\n","Epoch 11:\n","train Loss: 0.009 Acc: 1.0000\n","val Loss: 0.150 Acc: 0.9553\n","Epoch 12:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.183 Acc: 0.9447\n","Epoch 13:\n","train Loss: 0.012 Acc: 1.0000\n","val Loss: 0.147 Acc: 0.9553\n","Epoch 14:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.174 Acc: 0.9500\n","Epoch 15:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.147 Acc: 0.9605\n","Epoch 16:\n","train Loss: 0.000 Acc: 1.0000\n","val Loss: 0.146 Acc: 0.9605\n","Epoch 17:\n","train Loss: 0.000 Acc: 1.0000\n","val Loss: 0.144 Acc: 0.9618\n","Epoch 18:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.143 Acc: 0.9618\n","Epoch 19:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.143 Acc: 0.9645\n","Epoch 20:\n","train Loss: 0.000 Acc: 1.0000\n","val Loss: 0.145 Acc: 0.9658\n","Epoch 21:\n","train Loss: 0.000 Acc: 1.0000\n","val Loss: 0.171 Acc: 0.9592\n","Epoch 22:\n","train Loss: 0.000 Acc: 1.0000\n","val Loss: 0.143 Acc: 0.9645\n","Epoch 23:\n","train Loss: 0.000 Acc: 1.0000\n","val Loss: 0.143 Acc: 0.9658\n","Epoch 24:\n","train Loss: 0.000 Acc: 1.0000\n","val Loss: 0.143 Acc: 0.9671\n","Epoch 25:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.144 Acc: 0.9671\n","Parameters set 3/24\n","(0.01, 0.9, 0.01, 0.0001, False, 15)\n","Epoch 0:\n","train Loss: 0.613 Acc: 0.6500\n","val Loss: 0.466 Acc: 0.8750\n","Epoch 1:\n","train Loss: 0.331 Acc: 0.8750\n","val Loss: 0.269 Acc: 0.8921\n","Epoch 2:\n","train Loss: 0.142 Acc: 0.9750\n","val Loss: 0.175 Acc: 0.9487\n","Epoch 3:\n","train Loss: 0.048 Acc: 1.0000\n","val Loss: 0.125 Acc: 0.9579\n","Epoch 4:\n","train Loss: 0.042 Acc: 1.0000\n","val Loss: 0.112 Acc: 0.9553\n","Epoch 5:\n","train Loss: 0.013 Acc: 1.0000\n","val Loss: 0.102 Acc: 0.9592\n","Epoch 6:\n","train Loss: 0.013 Acc: 1.0000\n","val Loss: 0.099 Acc: 0.9605\n","Epoch 7:\n","train Loss: 0.011 Acc: 1.0000\n","val Loss: 0.099 Acc: 0.9618\n","Epoch 8:\n","train Loss: 0.039 Acc: 1.0000\n","val Loss: 0.098 Acc: 0.9605\n","Epoch 9:\n","train Loss: 0.010 Acc: 1.0000\n","val Loss: 0.095 Acc: 0.9592\n","Epoch 10:\n","train Loss: 0.009 Acc: 1.0000\n","val Loss: 0.094 Acc: 0.9592\n","Epoch 11:\n","train Loss: 0.007 Acc: 1.0000\n","val Loss: 0.100 Acc: 0.9566\n","Epoch 12:\n","train Loss: 0.005 Acc: 1.0000\n","val Loss: 0.089 Acc: 0.9632\n","Epoch 13:\n","train Loss: 0.007 Acc: 1.0000\n","val Loss: 0.088 Acc: 0.9632\n","Epoch 14:\n","train Loss: 0.033 Acc: 1.0000\n","val Loss: 0.085 Acc: 0.9684\n","Epoch 15:\n","train Loss: 0.010 Acc: 1.0000\n","val Loss: 0.091 Acc: 0.9632\n","Epoch 16:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.088 Acc: 0.9671\n","Epoch 17:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.092 Acc: 0.9684\n","Epoch 18:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.094 Acc: 0.9671\n","Epoch 19:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.096 Acc: 0.9684\n","Epoch 20:\n","train Loss: 0.007 Acc: 1.0000\n","val Loss: 0.096 Acc: 0.9684\n","Epoch 21:\n","train Loss: 0.007 Acc: 1.0000\n","val Loss: 0.102 Acc: 0.9618\n","Epoch 22:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.096 Acc: 0.9671\n","Epoch 23:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.097 Acc: 0.9658\n","Epoch 24:\n","train Loss: 0.003 Acc: 1.0000\n","val Loss: 0.096 Acc: 0.9658\n","Epoch 25:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.094 Acc: 0.9684\n","Parameters set 4/24\n","(0.01, 0.9, 0.01, 1, False, 5)\n","Epoch 0:\n","train Loss: 0.766 Acc: 0.5500\n","val Loss: 0.733 Acc: 0.3908\n","Epoch 1:\n","train Loss: 0.466 Acc: 0.6750\n","val Loss: 0.559 Acc: 0.7934\n","Epoch 2:\n","train Loss: 0.250 Acc: 0.9750\n","val Loss: 0.501 Acc: 0.8763\n","Epoch 3:\n","train Loss: 0.278 Acc: 0.9250\n","val Loss: 0.476 Acc: 0.8395\n","Epoch 4:\n","train Loss: 0.186 Acc: 0.9500\n","val Loss: 0.652 Acc: 0.6566\n","Epoch 5:\n","train Loss: 0.117 Acc: 0.9750\n","val Loss: 0.678 Acc: 0.6618\n","Epoch 6:\n","train Loss: 0.026 Acc: 1.0000\n","val Loss: 0.688 Acc: 0.6566\n","Epoch 7:\n","train Loss: 0.020 Acc: 1.0000\n","val Loss: 0.686 Acc: 0.6553\n","Epoch 8:\n","train Loss: 0.026 Acc: 1.0000\n","val Loss: 0.689 Acc: 0.6342\n","Epoch 9:\n","train Loss: 0.022 Acc: 1.0000\n","val Loss: 0.694 Acc: 0.3487\n","Epoch 10:\n","train Loss: 0.066 Acc: 1.0000\n","val Loss: 0.697 Acc: 0.3487\n","Epoch 11:\n","train Loss: 0.082 Acc: 1.0000\n","val Loss: 0.696 Acc: 0.3434\n","Epoch 12:\n","train Loss: 0.127 Acc: 1.0000\n","val Loss: 0.696 Acc: 0.3382\n","Epoch 13:\n","train Loss: 0.134 Acc: 1.0000\n","val Loss: 0.695 Acc: 0.3487\n","Epoch 14:\n","train Loss: 0.270 Acc: 1.0000\n","val Loss: 0.689 Acc: 0.6566\n","Epoch 15:\n","train Loss: 0.605 Acc: 0.9000\n","val Loss: 0.685 Acc: 0.6618\n","Epoch 16:\n","train Loss: 0.692 Acc: 0.6250\n","val Loss: 0.684 Acc: 0.6566\n","Epoch 17:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.684 Acc: 0.6618\n","Epoch 18:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.684 Acc: 0.6618\n","Epoch 19:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.687 Acc: 0.6566\n","Epoch 20:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.690 Acc: 0.6513\n","Epoch 21:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.691 Acc: 0.6566\n","Epoch 22:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.691 Acc: 0.6566\n","Epoch 23:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.691 Acc: 0.6618\n","Epoch 24:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.692 Acc: 0.6513\n","Epoch 25:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.693 Acc: 0.6566\n","Parameters set 5/24\n","(0.01, 0.9, 0.01, 1, False, 15)\n","Epoch 0:\n","train Loss: 0.949 Acc: 0.3250\n","val Loss: 0.587 Acc: 0.7408\n","Epoch 1:\n","train Loss: 0.443 Acc: 0.7500\n","val Loss: 0.606 Acc: 0.7816\n","Epoch 2:\n","train Loss: 0.174 Acc: 0.9750\n","val Loss: 0.641 Acc: 0.6618\n","Epoch 3:\n","train Loss: 0.115 Acc: 0.9750\n","val Loss: 0.645 Acc: 0.6566\n","Epoch 4:\n","train Loss: 0.099 Acc: 0.9750\n","val Loss: 0.651 Acc: 0.6566\n","Epoch 5:\n","train Loss: 0.067 Acc: 1.0000\n","val Loss: 0.656 Acc: 0.6618\n","Epoch 6:\n","train Loss: 0.097 Acc: 1.0000\n","val Loss: 0.661 Acc: 0.6513\n","Epoch 7:\n","train Loss: 0.037 Acc: 1.0000\n","val Loss: 0.663 Acc: 0.6513\n","Epoch 8:\n","train Loss: 0.034 Acc: 1.0000\n","val Loss: 0.665 Acc: 0.6408\n","Epoch 9:\n","train Loss: 0.032 Acc: 1.0000\n","val Loss: 0.666 Acc: 0.6605\n","Epoch 10:\n","train Loss: 0.045 Acc: 1.0000\n","val Loss: 0.672 Acc: 0.6474\n","Epoch 11:\n","train Loss: 0.036 Acc: 1.0000\n","val Loss: 0.679 Acc: 0.6513\n","Epoch 12:\n","train Loss: 0.052 Acc: 1.0000\n","val Loss: 0.692 Acc: 0.6158\n","Epoch 13:\n","train Loss: 0.110 Acc: 1.0000\n","val Loss: 0.695 Acc: 0.3434\n","Epoch 14:\n","train Loss: 0.133 Acc: 1.0000\n","val Loss: 0.692 Acc: 0.6566\n","Epoch 15:\n","train Loss: 0.497 Acc: 0.9750\n","val Loss: 0.689 Acc: 0.6566\n","Epoch 16:\n","train Loss: 0.690 Acc: 0.6000\n","val Loss: 0.689 Acc: 0.6566\n","Epoch 17:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.690 Acc: 0.6566\n","Epoch 18:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.692 Acc: 0.6566\n","Epoch 19:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.692 Acc: 0.6513\n","Epoch 20:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.692 Acc: 0.6513\n","Epoch 21:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.692 Acc: 0.6618\n","Epoch 22:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.692 Acc: 0.6513\n","Epoch 23:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.692 Acc: 0.6566\n","Epoch 24:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.692 Acc: 0.6513\n","Epoch 25:\n","train Loss: 0.693 Acc: 0.5000\n","val Loss: 0.692 Acc: 0.6566\n","Parameters set 6/24\n","(0.01, 0, 0.01, 0.1, False, 5)\n","Epoch 0:\n","train Loss: 0.706 Acc: 0.4750\n","val Loss: 0.539 Acc: 0.6645\n","Epoch 1:\n","train Loss: 0.413 Acc: 0.8250\n","val Loss: 0.449 Acc: 0.8776\n","Epoch 2:\n","train Loss: 0.373 Acc: 0.9250\n","val Loss: 0.446 Acc: 0.8763\n","Epoch 3:\n","train Loss: 0.367 Acc: 0.9750\n","val Loss: 0.425 Acc: 0.9105\n","Epoch 4:\n","train Loss: 0.331 Acc: 0.9750\n","val Loss: 0.369 Acc: 0.9382\n","Epoch 5:\n","train Loss: 0.293 Acc: 0.9750\n","val Loss: 0.303 Acc: 0.9276\n","Epoch 6:\n","train Loss: 0.280 Acc: 0.9000\n","val Loss: 0.278 Acc: 0.9474\n","Epoch 7:\n","train Loss: 0.189 Acc: 1.0000\n","val Loss: 0.279 Acc: 0.9500\n","Epoch 8:\n","train Loss: 0.222 Acc: 0.9750\n","val Loss: 0.281 Acc: 0.9487\n","Epoch 9:\n","train Loss: 0.178 Acc: 0.9750\n","val Loss: 0.247 Acc: 0.9461\n","Epoch 10:\n","train Loss: 0.284 Acc: 0.9250\n","val Loss: 0.241 Acc: 0.9250\n","Epoch 11:\n","train Loss: 0.140 Acc: 1.0000\n","val Loss: 0.210 Acc: 0.9513\n","Epoch 12:\n","train Loss: 0.151 Acc: 1.0000\n","val Loss: 0.213 Acc: 0.9526\n","Epoch 13:\n","train Loss: 0.135 Acc: 1.0000\n","val Loss: 0.211 Acc: 0.9539\n","Epoch 14:\n","train Loss: 0.140 Acc: 1.0000\n","val Loss: 0.196 Acc: 0.9553\n","Epoch 15:\n","train Loss: 0.122 Acc: 1.0000\n","val Loss: 0.192 Acc: 0.9592\n","Epoch 16:\n","train Loss: 0.081 Acc: 1.0000\n","val Loss: 0.188 Acc: 0.9592\n","Epoch 17:\n","train Loss: 0.088 Acc: 1.0000\n","val Loss: 0.184 Acc: 0.9605\n","Epoch 18:\n","train Loss: 0.087 Acc: 0.9750\n","val Loss: 0.182 Acc: 0.9618\n","Epoch 19:\n","train Loss: 0.128 Acc: 1.0000\n","val Loss: 0.192 Acc: 0.9539\n","Epoch 20:\n","train Loss: 0.069 Acc: 1.0000\n","val Loss: 0.169 Acc: 0.9618\n","Epoch 21:\n","train Loss: 0.121 Acc: 1.0000\n","val Loss: 0.166 Acc: 0.9632\n","Epoch 22:\n","train Loss: 0.066 Acc: 1.0000\n","val Loss: 0.162 Acc: 0.9632\n","Epoch 23:\n","train Loss: 0.055 Acc: 1.0000\n","val Loss: 0.164 Acc: 0.9632\n","Epoch 24:\n","train Loss: 0.055 Acc: 1.0000\n","val Loss: 0.158 Acc: 0.9618\n","Epoch 25:\n","train Loss: 0.041 Acc: 1.0000\n","val Loss: 0.155 Acc: 0.9632\n","Parameters set 7/24\n","(0.01, 0, 0.01, 0.1, False, 15)\n","Epoch 0:\n","train Loss: 0.928 Acc: 0.3750\n","val Loss: 0.775 Acc: 0.6408\n","Epoch 1:\n","train Loss: 1.148 Acc: 0.4000\n","val Loss: 0.412 Acc: 0.7500\n","Epoch 2:\n","train Loss: 0.411 Acc: 0.7750\n","val Loss: 0.335 Acc: 0.9316\n","Epoch 3:\n","train Loss: 0.287 Acc: 0.9500\n","val Loss: 0.284 Acc: 0.9461\n","Epoch 4:\n","train Loss: 0.244 Acc: 0.9750\n","val Loss: 0.280 Acc: 0.9434\n","Epoch 5:\n","train Loss: 0.208 Acc: 1.0000\n","val Loss: 0.266 Acc: 0.9500\n","Epoch 6:\n","train Loss: 0.199 Acc: 0.9750\n","val Loss: 0.266 Acc: 0.9539\n","Epoch 7:\n","train Loss: 0.185 Acc: 1.0000\n","val Loss: 0.268 Acc: 0.9592\n","Epoch 8:\n","train Loss: 0.203 Acc: 1.0000\n","val Loss: 0.266 Acc: 0.9605\n","Epoch 9:\n","train Loss: 0.197 Acc: 1.0000\n","val Loss: 0.267 Acc: 0.9592\n","Epoch 10:\n","train Loss: 0.187 Acc: 0.9750\n","val Loss: 0.262 Acc: 0.9579\n","Epoch 11:\n","train Loss: 0.179 Acc: 1.0000\n","val Loss: 0.255 Acc: 0.9553\n","Epoch 12:\n","train Loss: 0.179 Acc: 1.0000\n","val Loss: 0.229 Acc: 0.9592\n","Epoch 13:\n","train Loss: 0.145 Acc: 1.0000\n","val Loss: 0.208 Acc: 0.9632\n","Epoch 14:\n","train Loss: 0.131 Acc: 1.0000\n","val Loss: 0.189 Acc: 0.9658\n","Epoch 15:\n","train Loss: 0.095 Acc: 1.0000\n","val Loss: 0.182 Acc: 0.9645\n","Epoch 16:\n","train Loss: 0.118 Acc: 1.0000\n","val Loss: 0.184 Acc: 0.9618\n","Epoch 17:\n","train Loss: 0.107 Acc: 1.0000\n","val Loss: 0.173 Acc: 0.9658\n","Epoch 18:\n","train Loss: 0.063 Acc: 1.0000\n","val Loss: 0.166 Acc: 0.9658\n","Epoch 19:\n","train Loss: 0.077 Acc: 1.0000\n","val Loss: 0.162 Acc: 0.9671\n","Epoch 20:\n","train Loss: 0.235 Acc: 0.9750\n","val Loss: 0.155 Acc: 0.9684\n","Epoch 21:\n","train Loss: 0.068 Acc: 1.0000\n","val Loss: 0.154 Acc: 0.9684\n","Epoch 22:\n","train Loss: 0.070 Acc: 1.0000\n","val Loss: 0.152 Acc: 0.9697\n","Epoch 23:\n","train Loss: 0.059 Acc: 1.0000\n","val Loss: 0.151 Acc: 0.9684\n","Epoch 24:\n","train Loss: 0.052 Acc: 1.0000\n","val Loss: 0.152 Acc: 0.9671\n","Epoch 25:\n","train Loss: 0.078 Acc: 1.0000\n","val Loss: 0.153 Acc: 0.9697\n","Parameters set 8/24\n","(0.01, 0, 0.01, 0.0001, False, 5)\n","Epoch 0:\n","train Loss: 0.837 Acc: 0.5000\n","val Loss: 0.911 Acc: 0.3632\n","Epoch 1:\n","train Loss: 0.543 Acc: 0.7500\n","val Loss: 0.439 Acc: 0.8763\n","Epoch 2:\n","train Loss: 0.388 Acc: 0.9750\n","val Loss: 0.432 Acc: 0.8829\n","Epoch 3:\n","train Loss: 0.409 Acc: 0.9500\n","val Loss: 0.428 Acc: 0.8961\n","Epoch 4:\n","train Loss: 0.343 Acc: 0.9750\n","val Loss: 0.385 Acc: 0.9105\n","Epoch 5:\n","train Loss: 0.523 Acc: 0.7500\n","val Loss: 0.452 Acc: 0.7934\n","Epoch 6:\n","train Loss: 0.243 Acc: 0.9750\n","val Loss: 0.281 Acc: 0.9421\n","Epoch 7:\n","train Loss: 0.180 Acc: 1.0000\n","val Loss: 0.270 Acc: 0.9513\n","Epoch 8:\n","train Loss: 0.178 Acc: 1.0000\n","val Loss: 0.252 Acc: 0.9618\n","Epoch 9:\n","train Loss: 0.264 Acc: 0.9250\n","val Loss: 0.324 Acc: 0.9039\n","Epoch 10:\n","train Loss: 0.198 Acc: 0.9750\n","val Loss: 0.212 Acc: 0.9658\n","Epoch 11:\n","train Loss: 0.144 Acc: 1.0000\n","val Loss: 0.198 Acc: 0.9658\n","Epoch 12:\n","train Loss: 0.105 Acc: 1.0000\n","val Loss: 0.199 Acc: 0.9671\n","Epoch 13:\n","train Loss: 0.097 Acc: 1.0000\n","val Loss: 0.197 Acc: 0.9671\n","Epoch 14:\n","train Loss: 0.162 Acc: 1.0000\n","val Loss: 0.207 Acc: 0.9579\n","Epoch 15:\n","train Loss: 0.100 Acc: 1.0000\n","val Loss: 0.182 Acc: 0.9592\n","Epoch 16:\n","train Loss: 0.170 Acc: 0.9500\n","val Loss: 0.163 Acc: 0.9711\n","Epoch 17:\n","train Loss: 0.217 Acc: 1.0000\n","val Loss: 0.174 Acc: 0.9632\n","Epoch 18:\n","train Loss: 0.068 Acc: 1.0000\n","val Loss: 0.162 Acc: 0.9684\n","Epoch 19:\n","train Loss: 0.090 Acc: 1.0000\n","val Loss: 0.151 Acc: 0.9724\n","Epoch 20:\n","train Loss: 0.064 Acc: 1.0000\n","val Loss: 0.146 Acc: 0.9737\n","Epoch 21:\n","train Loss: 0.113 Acc: 1.0000\n","val Loss: 0.142 Acc: 0.9697\n","Epoch 22:\n","train Loss: 0.051 Acc: 1.0000\n","val Loss: 0.142 Acc: 0.9684\n","Epoch 23:\n","train Loss: 0.053 Acc: 1.0000\n","val Loss: 0.140 Acc: 0.9697\n","Epoch 24:\n","train Loss: 0.051 Acc: 1.0000\n","val Loss: 0.136 Acc: 0.9724\n","Epoch 25:\n","train Loss: 0.042 Acc: 1.0000\n","val Loss: 0.134 Acc: 0.9737\n","Parameters set 9/24\n","(0.01, 0, 0.01, 0.0001, False, 15)\n","Epoch 0:\n","train Loss: 0.755 Acc: 0.5250\n","val Loss: 0.598 Acc: 0.7500\n","Epoch 1:\n","train Loss: 0.492 Acc: 0.8750\n","val Loss: 0.558 Acc: 0.7197\n","Epoch 2:\n","train Loss: 0.414 Acc: 0.8500\n","val Loss: 0.456 Acc: 0.8618\n","Epoch 3:\n","train Loss: 0.466 Acc: 0.7500\n","val Loss: 0.406 Acc: 0.8868\n","Epoch 4:\n","train Loss: 0.254 Acc: 1.0000\n","val Loss: 0.336 Acc: 0.9276\n","Epoch 5:\n","train Loss: 0.248 Acc: 1.0000\n","val Loss: 0.326 Acc: 0.9276\n","Epoch 6:\n","train Loss: 0.207 Acc: 1.0000\n","val Loss: 0.321 Acc: 0.9263\n","Epoch 7:\n","train Loss: 0.197 Acc: 1.0000\n","val Loss: 0.321 Acc: 0.9329\n","Epoch 8:\n","train Loss: 0.193 Acc: 1.0000\n","val Loss: 0.318 Acc: 0.9408\n","Epoch 9:\n","train Loss: 0.219 Acc: 1.0000\n","val Loss: 0.312 Acc: 0.9447\n","Epoch 10:\n","train Loss: 0.183 Acc: 1.0000\n","val Loss: 0.302 Acc: 0.9461\n","Epoch 11:\n","train Loss: 0.171 Acc: 1.0000\n","val Loss: 0.283 Acc: 0.9474\n","Epoch 12:\n","train Loss: 0.159 Acc: 1.0000\n","val Loss: 0.263 Acc: 0.9513\n","Epoch 13:\n","train Loss: 0.159 Acc: 0.9750\n","val Loss: 0.255 Acc: 0.9579\n","Epoch 14:\n","train Loss: 0.246 Acc: 0.9500\n","val Loss: 0.253 Acc: 0.9118\n","Epoch 15:\n","train Loss: 0.126 Acc: 1.0000\n","val Loss: 0.199 Acc: 0.9605\n","Epoch 16:\n","train Loss: 0.088 Acc: 1.0000\n","val Loss: 0.189 Acc: 0.9645\n","Epoch 17:\n","train Loss: 0.155 Acc: 0.9750\n","val Loss: 0.198 Acc: 0.9592\n","Epoch 18:\n","train Loss: 0.129 Acc: 1.0000\n","val Loss: 0.183 Acc: 0.9618\n","Epoch 19:\n","train Loss: 0.062 Acc: 1.0000\n","val Loss: 0.179 Acc: 0.9579\n","Epoch 20:\n","train Loss: 0.057 Acc: 1.0000\n","val Loss: 0.174 Acc: 0.9632\n","Epoch 21:\n","train Loss: 0.110 Acc: 1.0000\n","val Loss: 0.180 Acc: 0.9579\n","Epoch 22:\n","train Loss: 0.058 Acc: 1.0000\n","val Loss: 0.170 Acc: 0.9632\n","Epoch 23:\n","train Loss: 0.079 Acc: 1.0000\n","val Loss: 0.180 Acc: 0.9579\n","Epoch 24:\n","train Loss: 0.108 Acc: 1.0000\n","val Loss: 0.172 Acc: 0.9632\n","Epoch 25:\n","train Loss: 0.063 Acc: 1.0000\n","val Loss: 0.167 Acc: 0.9645\n","Parameters set 10/24\n","(0.01, 0, 0.01, 1, False, 5)\n","Epoch 0:\n","train Loss: 0.669 Acc: 0.5500\n","val Loss: 0.649 Acc: 0.6487\n","Epoch 1:\n","train Loss: 0.489 Acc: 0.7750\n","val Loss: 0.645 Acc: 0.6263\n","Epoch 2:\n","train Loss: 0.403 Acc: 0.9750\n","val Loss: 0.607 Acc: 0.7145\n","Epoch 3:\n","train Loss: 0.402 Acc: 0.9500\n","val Loss: 0.581 Acc: 0.7645\n","Epoch 4:\n","train Loss: 0.345 Acc: 0.9500\n","val Loss: 0.537 Acc: 0.8184\n","Epoch 5:\n","train Loss: 0.313 Acc: 0.9750\n","val Loss: 0.501 Acc: 0.7895\n","Epoch 6:\n","train Loss: 0.395 Acc: 0.8000\n","val Loss: 0.492 Acc: 0.8539\n","Epoch 7:\n","train Loss: 0.259 Acc: 1.0000\n","val Loss: 0.455 Acc: 0.8763\n","Epoch 8:\n","train Loss: 0.267 Acc: 0.9750\n","val Loss: 0.445 Acc: 0.8987\n","Epoch 9:\n","train Loss: 0.241 Acc: 1.0000\n","val Loss: 0.428 Acc: 0.8737\n","Epoch 10:\n","train Loss: 0.429 Acc: 0.8500\n","val Loss: 0.551 Acc: 0.7579\n","Epoch 11:\n","train Loss: 0.215 Acc: 1.0000\n","val Loss: 0.470 Acc: 0.9171\n","Epoch 12:\n","train Loss: 0.178 Acc: 1.0000\n","val Loss: 0.415 Acc: 0.9250\n","Epoch 13:\n","train Loss: 0.175 Acc: 1.0000\n","val Loss: 0.389 Acc: 0.9289\n","Epoch 14:\n","train Loss: 0.166 Acc: 1.0000\n","val Loss: 0.406 Acc: 0.9237\n","Epoch 15:\n","train Loss: 0.144 Acc: 1.0000\n","val Loss: 0.453 Acc: 0.9145\n","Epoch 16:\n","train Loss: 0.277 Acc: 0.9250\n","val Loss: 0.447 Acc: 0.9132\n","Epoch 17:\n","train Loss: 0.123 Acc: 1.0000\n","val Loss: 0.385 Acc: 0.9224\n","Epoch 18:\n","train Loss: 0.174 Acc: 0.9750\n","val Loss: 0.357 Acc: 0.9184\n","Epoch 19:\n","train Loss: 0.132 Acc: 1.0000\n","val Loss: 0.390 Acc: 0.9500\n","Epoch 20:\n","train Loss: 0.126 Acc: 1.0000\n","val Loss: 0.448 Acc: 0.9303\n","Epoch 21:\n","train Loss: 0.115 Acc: 1.0000\n","val Loss: 0.438 Acc: 0.9447\n","Epoch 22:\n","train Loss: 0.110 Acc: 1.0000\n","val Loss: 0.373 Acc: 0.9500\n","Epoch 23:\n","train Loss: 0.161 Acc: 1.0000\n","val Loss: 0.350 Acc: 0.9487\n","Epoch 24:\n","train Loss: 0.129 Acc: 1.0000\n","val Loss: 0.386 Acc: 0.9526\n","Epoch 25:\n","train Loss: 0.167 Acc: 1.0000\n","val Loss: 0.449 Acc: 0.9474\n","Parameters set 11/24\n","(0.01, 0, 0.01, 1, False, 15)\n","Epoch 0:\n","train Loss: 0.733 Acc: 0.5000\n","val Loss: 0.666 Acc: 0.5618\n","Epoch 1:\n","train Loss: 0.417 Acc: 0.7750\n","val Loss: 0.500 Acc: 0.7079\n","Epoch 2:\n","train Loss: 0.336 Acc: 0.9500\n","val Loss: 0.463 Acc: 0.8434\n","Epoch 3:\n","train Loss: 0.243 Acc: 1.0000\n","val Loss: 0.446 Acc: 0.9079\n","Epoch 4:\n","train Loss: 0.225 Acc: 1.0000\n","val Loss: 0.422 Acc: 0.9224\n","Epoch 5:\n","train Loss: 0.245 Acc: 1.0000\n","val Loss: 0.402 Acc: 0.9224\n","Epoch 6:\n","train Loss: 0.207 Acc: 1.0000\n","val Loss: 0.364 Acc: 0.9395\n","Epoch 7:\n","train Loss: 0.242 Acc: 0.9750\n","val Loss: 0.341 Acc: 0.9487\n","Epoch 8:\n","train Loss: 0.247 Acc: 1.0000\n","val Loss: 0.321 Acc: 0.9539\n","Epoch 9:\n","train Loss: 0.186 Acc: 1.0000\n","val Loss: 0.309 Acc: 0.9539\n","Epoch 10:\n","train Loss: 0.199 Acc: 1.0000\n","val Loss: 0.300 Acc: 0.9566\n","Epoch 11:\n","train Loss: 0.199 Acc: 1.0000\n","val Loss: 0.298 Acc: 0.9605\n","Epoch 12:\n","train Loss: 0.258 Acc: 0.9750\n","val Loss: 0.306 Acc: 0.9500\n","Epoch 13:\n","train Loss: 0.168 Acc: 1.0000\n","val Loss: 0.358 Acc: 0.9526\n","Epoch 14:\n","train Loss: 0.139 Acc: 1.0000\n","val Loss: 0.443 Acc: 0.9303\n","Epoch 15:\n","train Loss: 0.130 Acc: 1.0000\n","val Loss: 0.512 Acc: 0.9145\n","Epoch 16:\n","train Loss: 0.128 Acc: 1.0000\n","val Loss: 0.570 Acc: 0.8079\n","Epoch 17:\n","train Loss: 0.103 Acc: 1.0000\n","val Loss: 0.585 Acc: 0.7974\n","Epoch 18:\n","train Loss: 0.171 Acc: 1.0000\n","val Loss: 0.575 Acc: 0.8079\n","Epoch 19:\n","train Loss: 0.095 Acc: 1.0000\n","val Loss: 0.536 Acc: 0.8592\n","Epoch 20:\n","train Loss: 0.085 Acc: 1.0000\n","val Loss: 0.465 Acc: 0.9171\n","Epoch 21:\n","train Loss: 0.085 Acc: 1.0000\n","val Loss: 0.378 Acc: 0.9474\n","Epoch 22:\n","train Loss: 0.097 Acc: 1.0000\n","val Loss: 0.303 Acc: 0.9592\n","Epoch 23:\n","train Loss: 0.092 Acc: 1.0000\n","val Loss: 0.259 Acc: 0.9658\n","Epoch 24:\n","train Loss: 0.087 Acc: 1.0000\n","val Loss: 0.236 Acc: 0.9658\n","Epoch 25:\n","train Loss: 0.109 Acc: 1.0000\n","val Loss: 0.234 Acc: 0.9658\n","Parameters set 12/24\n","(0.1, 0.9, 0.01, 0.1, False, 5)\n","Epoch 0:\n","train Loss: 2.385 Acc: 0.5500\n","val Loss: 9.126 Acc: 0.3487\n","Epoch 1:\n","train Loss: 4.116 Acc: 0.7000\n","val Loss: 1.027 Acc: 0.8053\n","Epoch 2:\n","train Loss: 1.721 Acc: 0.7750\n","val Loss: 0.480 Acc: 0.8724\n","Epoch 3:\n","train Loss: 0.153 Acc: 0.9750\n","val Loss: 34.406 Acc: 0.5474\n","Epoch 4:\n","train Loss: 1.550 Acc: 0.8750\n","val Loss: 163.834 Acc: 0.6461\n","Epoch 5:\n","train Loss: 7.184 Acc: 0.5250\n","val Loss: 434056.572 Acc: 0.6566\n","Epoch 6:\n","train Loss: 2.360 Acc: 0.5000\n","val Loss: 56904.509 Acc: 0.6513\n","Epoch 7:\n","train Loss: 1.051 Acc: 0.5750\n","val Loss: 1200.710 Acc: 0.3382\n","Epoch 8:\n","train Loss: 0.432 Acc: 0.7250\n","val Loss: 540.751 Acc: 0.6566\n","Epoch 9:\n","train Loss: 2.910 Acc: 0.5250\n","val Loss: 5945.846 Acc: 0.6618\n","Epoch 10:\n","train Loss: 1.600 Acc: 0.6750\n","val Loss: 422.010 Acc: 0.6461\n","Epoch 11:\n","train Loss: 1.083 Acc: 0.6500\n","val Loss: 38.373 Acc: 0.6513\n","Epoch 12:\n","train Loss: 0.704 Acc: 0.7500\n","val Loss: 6.066 Acc: 0.6526\n","Epoch 13:\n","train Loss: 0.671 Acc: 0.7750\n","val Loss: 0.935 Acc: 0.7013\n","Epoch 14:\n","train Loss: 0.449 Acc: 0.8500\n","val Loss: 0.844 Acc: 0.4303\n","Epoch 15:\n","train Loss: 1.271 Acc: 0.5000\n","val Loss: 0.928 Acc: 0.6566\n","Epoch 16:\n","train Loss: 0.821 Acc: 0.5000\n","val Loss: 0.642 Acc: 0.6513\n","Epoch 17:\n","train Loss: 0.644 Acc: 0.6500\n","val Loss: 0.627 Acc: 0.6513\n","Epoch 18:\n","train Loss: 0.454 Acc: 0.6750\n","val Loss: 0.637 Acc: 0.6513\n","Epoch 19:\n","train Loss: 0.408 Acc: 0.8750\n","val Loss: 0.944 Acc: 0.3382\n","Epoch 20:\n","train Loss: 0.484 Acc: 0.7250\n","val Loss: 1.084 Acc: 0.3434\n","Epoch 21:\n","train Loss: 0.669 Acc: 0.5250\n","val Loss: 1.071 Acc: 0.3487\n","Epoch 22:\n","train Loss: 0.718 Acc: 0.5000\n","val Loss: 1.067 Acc: 0.3434\n","Epoch 23:\n","train Loss: 0.699 Acc: 0.5000\n","val Loss: 0.995 Acc: 0.3487\n","Epoch 24:\n","train Loss: 0.638 Acc: 0.5250\n","val Loss: 0.794 Acc: 0.3434\n","Epoch 25:\n","train Loss: 0.551 Acc: 0.8000\n","val Loss: 0.670 Acc: 0.6513\n","Parameters set 13/24\n","(0.1, 0.9, 0.01, 0.1, False, 15)\n","Epoch 0:\n","train Loss: 4.188 Acc: 0.4500\n","val Loss: 11.956 Acc: 0.3487\n","Epoch 1:\n","train Loss: 7.056 Acc: 0.6000\n","val Loss: 135.274 Acc: 0.6171\n","Epoch 2:\n","train Loss: 6.579 Acc: 0.4500\n","val Loss: 31453610826670255602925568.000 Acc: 0.6513\n","Epoch 3:\n","train Loss: 7.027 Acc: 0.5000\n","val Loss: 983690193250555789312.000 Acc: 0.6618\n","Epoch 4:\n","train Loss: 2.406 Acc: 0.5750\n","val Loss: 6395730081253.053 Acc: 0.3487\n","Epoch 5:\n","train Loss: 1.133 Acc: 0.7500\n","val Loss: 244300801.368 Acc: 0.6566\n","Epoch 6:\n","train Loss: 1.204 Acc: 0.8000\n","val Loss: 783458.373 Acc: 0.6513\n","Epoch 7:\n","train Loss: 1.130 Acc: 0.8750\n","val Loss: 16861.327 Acc: 0.6618\n","Epoch 8:\n","train Loss: 1.099 Acc: 0.9000\n","val Loss: 1924.722 Acc: 0.6566\n","Epoch 9:\n","train Loss: 0.580 Acc: 0.8750\n","val Loss: 431.581 Acc: 0.6408\n","Epoch 10:\n","train Loss: 0.872 Acc: 0.7250\n","val Loss: 66.117 Acc: 0.6566\n","Epoch 11:\n","train Loss: 0.776 Acc: 0.7000\n","val Loss: 7.342 Acc: 0.6461\n","Epoch 12:\n","train Loss: 1.670 Acc: 0.5000\n","val Loss: 0.773 Acc: 0.6289\n","Epoch 13:\n","train Loss: 0.659 Acc: 0.6500\n","val Loss: 1.183 Acc: 0.4039\n","Epoch 14:\n","train Loss: 0.608 Acc: 0.7500\n","val Loss: 0.706 Acc: 0.3947\n","Epoch 15:\n","train Loss: 0.390 Acc: 0.8500\n","val Loss: 0.647 Acc: 0.6513\n","Epoch 16:\n","train Loss: 0.517 Acc: 0.7000\n","val Loss: 0.652 Acc: 0.6566\n","Epoch 17:\n","train Loss: 0.575 Acc: 0.7500\n","val Loss: 0.699 Acc: 0.3382\n","Epoch 18:\n","train Loss: 0.632 Acc: 0.7750\n","val Loss: 0.712 Acc: 0.3487\n","Epoch 19:\n","train Loss: 0.699 Acc: 0.5000\n","val Loss: 0.719 Acc: 0.3487\n","Epoch 20:\n","train Loss: 0.707 Acc: 0.5000\n","val Loss: 0.722 Acc: 0.3382\n","Epoch 21:\n","train Loss: 0.704 Acc: 0.5000\n","val Loss: 0.721 Acc: 0.3382\n","Epoch 22:\n","train Loss: 0.699 Acc: 0.5250\n","val Loss: 0.720 Acc: 0.3487\n","Epoch 23:\n","train Loss: 0.701 Acc: 0.5250\n","val Loss: 0.721 Acc: 0.3382\n","Epoch 24:\n","train Loss: 0.694 Acc: 0.5250\n","val Loss: 0.717 Acc: 0.3487\n","Epoch 25:\n","train Loss: 0.683 Acc: 0.6250\n","val Loss: 0.712 Acc: 0.3434\n","Parameters set 14/24\n","(0.1, 0.9, 0.01, 0.0001, False, 5)\n","Epoch 0:\n","train Loss: 0.767 Acc: 0.6750\n","val Loss: 8.247 Acc: 0.6566\n","Epoch 1:\n","train Loss: 5.150 Acc: 0.7500\n","val Loss: 0.595 Acc: 0.9079\n","Epoch 2:\n","train Loss: 0.828 Acc: 0.8750\n","val Loss: 1.240 Acc: 0.8158\n","Epoch 3:\n","train Loss: 0.290 Acc: 0.9500\n","val Loss: 15.397 Acc: 0.5197\n","Epoch 4:\n","train Loss: 1.374 Acc: 0.8500\n","val Loss: 1066.531 Acc: 0.6513\n","Epoch 5:\n","train Loss: 8.006 Acc: 0.6500\n","val Loss: 474040200.421 Acc: 0.3382\n","Epoch 6:\n","train Loss: 4.631 Acc: 0.5250\n","val Loss: 76195183.684 Acc: 0.3382\n","Epoch 7:\n","train Loss: 2.617 Acc: 0.7500\n","val Loss: 76076.508 Acc: 0.3539\n","Epoch 8:\n","train Loss: 2.108 Acc: 0.6000\n","val Loss: 10840.994 Acc: 0.6618\n","Epoch 9:\n","train Loss: 4.427 Acc: 0.6500\n","val Loss: 48497226.408 Acc: 0.6566\n","Epoch 10:\n","train Loss: 4.528 Acc: 0.5500\n","val Loss: 183170387.579 Acc: 0.6408\n","Epoch 11:\n","train Loss: 1.443 Acc: 0.7750\n","val Loss: 3529963.533 Acc: 0.6618\n","Epoch 12:\n","train Loss: 0.827 Acc: 0.8000\n","val Loss: 42271.920 Acc: 0.6618\n","Epoch 13:\n","train Loss: 0.571 Acc: 0.8250\n","val Loss: 9402.019 Acc: 0.6566\n","Epoch 14:\n","train Loss: 2.366 Acc: 0.7750\n","val Loss: 35140.007 Acc: 0.3434\n","Epoch 15:\n","train Loss: 1.137 Acc: 0.8500\n","val Loss: 203594.862 Acc: 0.3434\n","Epoch 16:\n","train Loss: 8.553 Acc: 0.7250\n","val Loss: 40363.429 Acc: 0.3434\n","Epoch 17:\n","train Loss: 2.216 Acc: 0.7750\n","val Loss: 6664.928 Acc: 0.3487\n","Epoch 18:\n","train Loss: 1.141 Acc: 0.9250\n","val Loss: 3025.368 Acc: 0.3434\n","Epoch 19:\n","train Loss: 1.716 Acc: 0.7500\n","val Loss: 7094.998 Acc: 0.3382\n","Epoch 20:\n","train Loss: 3.036 Acc: 0.7000\n","val Loss: 5602.020 Acc: 0.3434\n","Epoch 21:\n","train Loss: 3.548 Acc: 0.6000\n","val Loss: 1362.729 Acc: 0.4197\n","Epoch 22:\n","train Loss: 0.481 Acc: 0.9000\n","val Loss: 214.294 Acc: 0.5013\n","Epoch 23:\n","train Loss: 0.478 Acc: 0.8750\n","val Loss: 67.710 Acc: 0.5671\n","Epoch 24:\n","train Loss: 0.607 Acc: 0.7750\n","val Loss: 54.323 Acc: 0.7000\n","Epoch 25:\n","train Loss: 0.159 Acc: 0.9500\n","val Loss: 45.184 Acc: 0.7184\n","Parameters set 15/24\n","(0.1, 0.9, 0.01, 0.0001, False, 15)\n","Epoch 0:\n","train Loss: 2.734 Acc: 0.3500\n","val Loss: 22.085 Acc: 0.3434\n","Epoch 1:\n","train Loss: 8.006 Acc: 0.6500\n","val Loss: 36467.257 Acc: 0.6566\n","Epoch 2:\n","train Loss: 8.073 Acc: 0.5500\n","val Loss: 703854527730167185408.000 Acc: 0.3382\n","Epoch 3:\n","train Loss: 11.360 Acc: 0.4000\n","val Loss: 16066376933129887744.000 Acc: 0.6513\n","Epoch 4:\n","train Loss: 5.439 Acc: 0.5250\n","val Loss: 3051132204073008128.000 Acc: 0.6566\n","Epoch 5:\n","train Loss: 2.722 Acc: 0.5000\n","val Loss: 439754867119.158 Acc: 0.6566\n","Epoch 6:\n","train Loss: 0.872 Acc: 0.7000\n","val Loss: 70739528.368 Acc: 0.6566\n","Epoch 7:\n","train Loss: 0.787 Acc: 0.7750\n","val Loss: 873987.792 Acc: 0.6566\n","Epoch 8:\n","train Loss: 1.033 Acc: 0.7500\n","val Loss: 98419.178 Acc: 0.6513\n","Epoch 9:\n","train Loss: 0.507 Acc: 0.8000\n","val Loss: 57447.015 Acc: 0.6408\n","Epoch 10:\n","train Loss: 1.368 Acc: 0.5000\n","val Loss: 75369.024 Acc: 0.6461\n","Epoch 11:\n","train Loss: 1.554 Acc: 0.7000\n","val Loss: 147177.395 Acc: 0.6513\n","Epoch 12:\n","train Loss: 1.626 Acc: 0.7250\n","val Loss: 252114.804 Acc: 0.6618\n","Epoch 13:\n","train Loss: 2.861 Acc: 0.6500\n","val Loss: 419537.407 Acc: 0.6461\n","Epoch 14:\n","train Loss: 5.908 Acc: 0.6750\n","val Loss: 152587.653 Acc: 0.6461\n","Epoch 15:\n","train Loss: 1.798 Acc: 0.7000\n","val Loss: 111217.026 Acc: 0.6566\n","Epoch 16:\n","train Loss: 0.523 Acc: 0.8750\n","val Loss: 53797.134 Acc: 0.6618\n","Epoch 17:\n","train Loss: 1.119 Acc: 0.8750\n","val Loss: 20108.591 Acc: 0.6618\n","Epoch 18:\n","train Loss: 1.323 Acc: 0.8500\n","val Loss: 10541.953 Acc: 0.6513\n","Epoch 19:\n","train Loss: 0.850 Acc: 0.8750\n","val Loss: 3631.681 Acc: 0.6566\n","Epoch 20:\n","train Loss: 0.660 Acc: 0.8250\n","val Loss: 1202.803 Acc: 0.6645\n","Epoch 21:\n","train Loss: 0.664 Acc: 0.9000\n","val Loss: 408.580 Acc: 0.6763\n","Epoch 22:\n","train Loss: 0.522 Acc: 0.8750\n","val Loss: 163.230 Acc: 0.7000\n","Epoch 23:\n","train Loss: 0.496 Acc: 0.8750\n","val Loss: 73.402 Acc: 0.7474\n","Epoch 24:\n","train Loss: 0.367 Acc: 0.9500\n","val Loss: 37.189 Acc: 0.7539\n","Epoch 25:\n","train Loss: 0.275 Acc: 0.9750\n","val Loss: 19.857 Acc: 0.7566\n","Parameters set 16/24\n","(0.1, 0.9, 0.01, 1, False, 5)\n","Epoch 0:\n","train Loss: 3.360 Acc: 0.4500\n","val Loss: 0.982 Acc: 0.3434\n","Epoch 1:\n","train Loss: 2.672 Acc: 0.7500\n","val Loss: 0.752 Acc: 0.3382\n","Epoch 2:\n","train Loss: 0.389 Acc: 0.8250\n","val Loss: 0.710 Acc: 0.3434\n","Epoch 3:\n","train Loss: 0.304 Acc: 0.8750\n","val Loss: 0.695 Acc: 0.3434\n","Epoch 4:\n","train Loss: 0.833 Acc: 0.6250\n","val Loss: 0.689 Acc: 0.6566\n","Epoch 5:\n","train Loss: 0.754 Acc: 0.5000\n","val Loss: 534.258 Acc: 0.3487\n","Epoch 6:\n","train Loss: 0.835 Acc: 0.5500\n","val Loss: 1490.804 Acc: 0.3434\n","Epoch 7:\n","train Loss: 0.318 Acc: 0.9000\n","val Loss: 53.779 Acc: 0.3434\n","Epoch 8:\n","train Loss: 0.277 Acc: 0.8750\n","val Loss: 0.618 Acc: 0.6566\n","Epoch 9:\n","train Loss: 1.129 Acc: 0.7500\n","val Loss: 0.696 Acc: 0.3487\n","Epoch 10:\n","train Loss: 0.642 Acc: 0.5000\n","val Loss: 1.120 Acc: 0.6566\n","Epoch 11:\n","train Loss: 0.815 Acc: 0.4750\n","val Loss: 1.802 Acc: 0.3434\n","Epoch 12:\n","train Loss: 1.060 Acc: 0.4750\n","val Loss: 2.057 Acc: 0.3487\n","Epoch 13:\n","train Loss: 0.868 Acc: 0.4750\n","val Loss: 1.980 Acc: 0.6618\n","Epoch 14:\n","train Loss: 1.515 Acc: 0.5000\n","val Loss: 2.549 Acc: 0.6513\n","Epoch 15:\n","train Loss: 1.336 Acc: 0.5000\n","val Loss: 0.714 Acc: 0.3382\n","Epoch 16:\n","train Loss: 0.692 Acc: 0.5250\n","val Loss: 0.713 Acc: 0.3434\n","Epoch 17:\n","train Loss: 0.655 Acc: 0.5750\n","val Loss: 0.712 Acc: 0.3539\n","Epoch 18:\n","train Loss: 0.671 Acc: 0.5250\n","val Loss: 0.716 Acc: 0.3434\n","Epoch 19:\n","train Loss: 0.653 Acc: 0.6000\n","val Loss: 0.702 Acc: 0.3539\n","Epoch 20:\n","train Loss: 0.680 Acc: 0.5000\n","val Loss: 0.683 Acc: 0.6461\n","Epoch 21:\n","train Loss: 0.694 Acc: 0.5000\n","val Loss: 0.673 Acc: 0.6618\n","Epoch 22:\n","train Loss: 0.695 Acc: 0.5000\n","val Loss: 0.674 Acc: 0.6513\n","Epoch 23:\n","train Loss: 0.695 Acc: 0.5000\n","val Loss: 0.675 Acc: 0.6566\n","Epoch 24:\n","train Loss: 0.692 Acc: 0.5000\n","val Loss: 0.697 Acc: 0.3487\n","Epoch 25:\n","train Loss: 0.695 Acc: 0.5000\n","val Loss: 0.655 Acc: 0.6618\n","Parameters set 17/24\n","(0.1, 0.9, 0.01, 1, False, 15)\n","Epoch 0:\n","train Loss: 1.628 Acc: 0.4750\n","val Loss: 0.911 Acc: 0.6461\n","Epoch 1:\n","train Loss: 7.224 Acc: 0.6750\n","val Loss: 0.678 Acc: 0.6513\n","Epoch 2:\n","train Loss: 1.852 Acc: 0.3000\n","val Loss: 13.128 Acc: 0.3434\n","Epoch 3:\n","train Loss: 2.282 Acc: 0.5000\n","val Loss: 610431.311 Acc: 0.3487\n","Epoch 4:\n","train Loss: 3.548 Acc: 0.5000\n","val Loss: 17795.908 Acc: 0.3382\n","Epoch 5:\n","train Loss: 0.959 Acc: 0.5000\n","val Loss: 8.136 Acc: 0.4211\n","Epoch 6:\n","train Loss: 0.475 Acc: 0.7000\n","val Loss: 0.994 Acc: 0.6566\n","Epoch 7:\n","train Loss: 0.530 Acc: 0.7250\n","val Loss: 0.640 Acc: 0.6461\n","Epoch 8:\n","train Loss: 0.448 Acc: 0.8750\n","val Loss: 0.602 Acc: 0.6618\n","Epoch 9:\n","train Loss: 0.556 Acc: 0.8500\n","val Loss: 0.672 Acc: 0.6566\n","Epoch 10:\n","train Loss: 0.436 Acc: 0.8500\n","val Loss: 0.664 Acc: 0.6566\n","Epoch 11:\n","train Loss: 0.663 Acc: 0.4750\n","val Loss: 0.649 Acc: 0.6513\n","Epoch 12:\n","train Loss: 0.814 Acc: 0.5000\n","val Loss: 0.825 Acc: 0.6618\n","Epoch 13:\n","train Loss: 1.838 Acc: 0.4750\n","val Loss: 2049540.840 Acc: 0.6618\n","Epoch 14:\n","train Loss: 1.401 Acc: 0.5500\n","val Loss: 3133.317 Acc: 0.6566\n","Epoch 15:\n","train Loss: 1.057 Acc: 0.4750\n","val Loss: 0.859 Acc: 0.6618\n","Epoch 16:\n","train Loss: 0.748 Acc: 0.5000\n","val Loss: 0.699 Acc: 0.3434\n","Epoch 17:\n","train Loss: 0.697 Acc: 0.5000\n","val Loss: 0.691 Acc: 0.6513\n","Epoch 18:\n","train Loss: 0.678 Acc: 0.5000\n","val Loss: 0.677 Acc: 0.6513\n","Epoch 19:\n","train Loss: 0.670 Acc: 0.5750\n","val Loss: 0.673 Acc: 0.6566\n","Epoch 20:\n","train Loss: 0.635 Acc: 0.7000\n","val Loss: 0.673 Acc: 0.6461\n","Epoch 21:\n","train Loss: 0.601 Acc: 0.8250\n","val Loss: 0.669 Acc: 0.6618\n","Epoch 22:\n","train Loss: 0.572 Acc: 0.8750\n","val Loss: 0.669 Acc: 0.6618\n","Epoch 23:\n","train Loss: 0.569 Acc: 0.9000\n","val Loss: 0.672 Acc: 0.6461\n","Epoch 24:\n","train Loss: 0.540 Acc: 0.9500\n","val Loss: 0.676 Acc: 0.6566\n","Epoch 25:\n","train Loss: 0.549 Acc: 0.8750\n","val Loss: 0.699 Acc: 0.3539\n","Parameters set 18/24\n","(0.1, 0, 0.01, 0.1, False, 5)\n","Epoch 0:\n","train Loss: 3.638 Acc: 0.4250\n","val Loss: 22.656 Acc: 0.6566\n","Epoch 1:\n","train Loss: 16.141 Acc: 0.4000\n","val Loss: 3.557 Acc: 0.6697\n","Epoch 2:\n","train Loss: 1.021 Acc: 0.6250\n","val Loss: 0.328 Acc: 0.9013\n","Epoch 3:\n","train Loss: 0.516 Acc: 0.8000\n","val Loss: 0.177 Acc: 0.9368\n","Epoch 4:\n","train Loss: 0.028 Acc: 1.0000\n","val Loss: 0.124 Acc: 0.9553\n","Epoch 5:\n","train Loss: 0.023 Acc: 1.0000\n","val Loss: 0.141 Acc: 0.9566\n","Epoch 6:\n","train Loss: 0.017 Acc: 1.0000\n","val Loss: 0.144 Acc: 0.9579\n","Epoch 7:\n","train Loss: 0.015 Acc: 1.0000\n","val Loss: 0.133 Acc: 0.9513\n","Epoch 8:\n","train Loss: 0.010 Acc: 1.0000\n","val Loss: 0.143 Acc: 0.9474\n","Epoch 9:\n","train Loss: 0.010 Acc: 1.0000\n","val Loss: 0.153 Acc: 0.9553\n","Epoch 10:\n","train Loss: 0.008 Acc: 1.0000\n","val Loss: 0.206 Acc: 0.9579\n","Epoch 11:\n","train Loss: 0.010 Acc: 1.0000\n","val Loss: 0.210 Acc: 0.9618\n","Epoch 12:\n","train Loss: 0.014 Acc: 1.0000\n","val Loss: 0.161 Acc: 0.9579\n","Epoch 13:\n","train Loss: 0.013 Acc: 1.0000\n","val Loss: 0.150 Acc: 0.9553\n","Epoch 14:\n","train Loss: 0.009 Acc: 1.0000\n","val Loss: 0.183 Acc: 0.9618\n","Epoch 15:\n","train Loss: 0.015 Acc: 1.0000\n","val Loss: 0.248 Acc: 0.9618\n","Epoch 16:\n","train Loss: 0.009 Acc: 1.0000\n","val Loss: 0.250 Acc: 0.9618\n","Epoch 17:\n","train Loss: 0.005 Acc: 1.0000\n","val Loss: 0.188 Acc: 0.9632\n","Epoch 18:\n","train Loss: 0.005 Acc: 1.0000\n","val Loss: 0.165 Acc: 0.9566\n","Epoch 19:\n","train Loss: 0.006 Acc: 1.0000\n","val Loss: 0.209 Acc: 0.9579\n","Epoch 20:\n","train Loss: 0.055 Acc: 1.0000\n","val Loss: 0.309 Acc: 0.8579\n","Epoch 21:\n","train Loss: 0.010 Acc: 1.0000\n","val Loss: 0.293 Acc: 0.8671\n","Epoch 22:\n","train Loss: 0.027 Acc: 1.0000\n","val Loss: 0.221 Acc: 0.9211\n","Epoch 23:\n","train Loss: 0.010 Acc: 1.0000\n","val Loss: 0.187 Acc: 0.9408\n","Epoch 24:\n","train Loss: 0.013 Acc: 1.0000\n","val Loss: 0.247 Acc: 0.9329\n","Epoch 25:\n","train Loss: 0.049 Acc: 0.9750\n","val Loss: 0.326 Acc: 0.8171\n","Parameters set 19/24\n","(0.1, 0, 0.01, 0.1, False, 15)\n","Epoch 0:\n","train Loss: 2.767 Acc: 0.4750\n","val Loss: 20.649 Acc: 0.3434\n","Epoch 1:\n","train Loss: 7.870 Acc: 0.7750\n","val Loss: 6.014 Acc: 0.3632\n","Epoch 2:\n","train Loss: 0.078 Acc: 0.9500\n","val Loss: 2.084 Acc: 0.4289\n","Epoch 3:\n","train Loss: 0.137 Acc: 0.9000\n","val Loss: 1.010 Acc: 0.7066\n","Epoch 4:\n","train Loss: 0.095 Acc: 0.9500\n","val Loss: 0.526 Acc: 0.8066\n","Epoch 5:\n","train Loss: 0.009 Acc: 1.0000\n","val Loss: 0.313 Acc: 0.8895\n","Epoch 6:\n","train Loss: 0.006 Acc: 1.0000\n","val Loss: 0.207 Acc: 0.9276\n","Epoch 7:\n","train Loss: 0.026 Acc: 1.0000\n","val Loss: 0.159 Acc: 0.9447\n","Epoch 8:\n","train Loss: 0.163 Acc: 0.9750\n","val Loss: 0.137 Acc: 0.9395\n","Epoch 9:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.114 Acc: 0.9592\n","Epoch 10:\n","train Loss: 0.010 Acc: 1.0000\n","val Loss: 0.114 Acc: 0.9579\n","Epoch 11:\n","train Loss: 0.003 Acc: 1.0000\n","val Loss: 0.115 Acc: 0.9605\n","Epoch 12:\n","train Loss: 0.003 Acc: 1.0000\n","val Loss: 0.161 Acc: 0.9447\n","Epoch 13:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.270 Acc: 0.8763\n","Epoch 14:\n","train Loss: 0.007 Acc: 1.0000\n","val Loss: 0.351 Acc: 0.8250\n","Epoch 15:\n","train Loss: 0.005 Acc: 1.0000\n","val Loss: 0.473 Acc: 0.7316\n","Epoch 16:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.518 Acc: 0.7118\n","Epoch 17:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.544 Acc: 0.7026\n","Epoch 18:\n","train Loss: 0.007 Acc: 1.0000\n","val Loss: 0.522 Acc: 0.7145\n","Epoch 19:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.504 Acc: 0.7197\n","Epoch 20:\n","train Loss: 0.005 Acc: 1.0000\n","val Loss: 0.453 Acc: 0.7408\n","Epoch 21:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.386 Acc: 0.7908\n","Epoch 22:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.288 Acc: 0.8605\n","Epoch 23:\n","train Loss: 0.005 Acc: 1.0000\n","val Loss: 0.220 Acc: 0.9026\n","Epoch 24:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.191 Acc: 0.9263\n","Epoch 25:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.187 Acc: 0.9263\n","Parameters set 20/24\n","(0.1, 0, 0.01, 0.0001, False, 5)\n","Epoch 0:\n","train Loss: 4.570 Acc: 0.3750\n","val Loss: 15.194 Acc: 0.6513\n","Epoch 1:\n","train Loss: 11.300 Acc: 0.4500\n","val Loss: 6.068 Acc: 0.7803\n","Epoch 2:\n","train Loss: 0.316 Acc: 0.8750\n","val Loss: 0.934 Acc: 0.9000\n","Epoch 3:\n","train Loss: 0.081 Acc: 0.9250\n","val Loss: 0.301 Acc: 0.9487\n","Epoch 4:\n","train Loss: 0.089 Acc: 0.9500\n","val Loss: 0.134 Acc: 0.9737\n","Epoch 5:\n","train Loss: 0.008 Acc: 1.0000\n","val Loss: 0.117 Acc: 0.9763\n","Epoch 6:\n","train Loss: 0.022 Acc: 1.0000\n","val Loss: 0.102 Acc: 0.9776\n","Epoch 7:\n","train Loss: 0.007 Acc: 1.0000\n","val Loss: 0.100 Acc: 0.9763\n","Epoch 8:\n","train Loss: 0.009 Acc: 1.0000\n","val Loss: 0.100 Acc: 0.9763\n","Epoch 9:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.096 Acc: 0.9789\n","Epoch 10:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.098 Acc: 0.9763\n","Epoch 11:\n","train Loss: 0.043 Acc: 1.0000\n","val Loss: 0.091 Acc: 0.9776\n","Epoch 12:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.103 Acc: 0.9724\n","Epoch 13:\n","train Loss: 0.004 Acc: 1.0000\n","val Loss: 0.091 Acc: 0.9789\n","Epoch 14:\n","train Loss: 0.014 Acc: 1.0000\n","val Loss: 0.092 Acc: 0.9776\n","Epoch 15:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.093 Acc: 0.9776\n","Epoch 16:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.089 Acc: 0.9789\n","Epoch 17:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.089 Acc: 0.9789\n","Epoch 18:\n","train Loss: 0.003 Acc: 1.0000\n","val Loss: 0.088 Acc: 0.9789\n","Epoch 19:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.088 Acc: 0.9789\n","Epoch 20:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.087 Acc: 0.9789\n","Epoch 21:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.086 Acc: 0.9789\n","Epoch 22:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.088 Acc: 0.9789\n","Epoch 23:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.087 Acc: 0.9789\n","Epoch 24:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.087 Acc: 0.9789\n","Epoch 25:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.087 Acc: 0.9776\n","Parameters set 21/24\n","(0.1, 0, 0.01, 0.0001, False, 15)\n","Epoch 0:\n","train Loss: 3.164 Acc: 0.4750\n","val Loss: 17.143 Acc: 0.6618\n","Epoch 1:\n","train Loss: 14.479 Acc: 0.5000\n","val Loss: 509.369 Acc: 0.6566\n","Epoch 2:\n","train Loss: 4.662 Acc: 0.5500\n","val Loss: 1148.066 Acc: 0.3487\n","Epoch 3:\n","train Loss: 3.027 Acc: 0.7000\n","val Loss: 2.732 Acc: 0.6487\n","Epoch 4:\n","train Loss: 0.731 Acc: 0.8500\n","val Loss: 1.904 Acc: 0.6921\n","Epoch 5:\n","train Loss: 0.515 Acc: 0.8500\n","val Loss: 0.974 Acc: 0.8882\n","Epoch 6:\n","train Loss: 0.009 Acc: 1.0000\n","val Loss: 0.845 Acc: 0.9026\n","Epoch 7:\n","train Loss: 0.010 Acc: 1.0000\n","val Loss: 0.768 Acc: 0.9105\n","Epoch 8:\n","train Loss: 0.013 Acc: 1.0000\n","val Loss: 0.703 Acc: 0.9118\n","Epoch 9:\n","train Loss: 0.014 Acc: 1.0000\n","val Loss: 0.654 Acc: 0.9105\n","Epoch 10:\n","train Loss: 0.007 Acc: 1.0000\n","val Loss: 0.605 Acc: 0.9105\n","Epoch 11:\n","train Loss: 0.006 Acc: 1.0000\n","val Loss: 0.609 Acc: 0.9079\n","Epoch 12:\n","train Loss: 0.005 Acc: 1.0000\n","val Loss: 0.540 Acc: 0.9145\n","Epoch 13:\n","train Loss: 0.007 Acc: 1.0000\n","val Loss: 0.557 Acc: 0.9026\n","Epoch 14:\n","train Loss: 0.004 Acc: 1.0000\n","val Loss: 0.496 Acc: 0.9197\n","Epoch 15:\n","train Loss: 0.009 Acc: 1.0000\n","val Loss: 0.429 Acc: 0.9250\n","Epoch 16:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.428 Acc: 0.9250\n","Epoch 17:\n","train Loss: 0.004 Acc: 1.0000\n","val Loss: 0.429 Acc: 0.9250\n","Epoch 18:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.423 Acc: 0.9250\n","Epoch 19:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.426 Acc: 0.9250\n","Epoch 20:\n","train Loss: 0.007 Acc: 1.0000\n","val Loss: 0.429 Acc: 0.9250\n","Epoch 21:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.428 Acc: 0.9250\n","Epoch 22:\n","train Loss: 0.005 Acc: 1.0000\n","val Loss: 0.430 Acc: 0.9250\n","Epoch 23:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.428 Acc: 0.9250\n","Epoch 24:\n","train Loss: 0.001 Acc: 1.0000\n","val Loss: 0.428 Acc: 0.9250\n","Epoch 25:\n","train Loss: 0.002 Acc: 1.0000\n","val Loss: 0.438 Acc: 0.9250\n","Parameters set 22/24\n","(0.1, 0, 0.01, 1, False, 5)\n","Epoch 0:\n","train Loss: 2.628 Acc: 0.5500\n","val Loss: 0.859 Acc: 0.6513\n","Epoch 1:\n","train Loss: 6.128 Acc: 0.6250\n","val Loss: 0.721 Acc: 0.3382\n","Epoch 2:\n","train Loss: 0.386 Acc: 0.9000\n","val Loss: 0.692 Acc: 0.4868\n","Epoch 3:\n","train Loss: 0.161 Acc: 0.9000\n","val Loss: 0.658 Acc: 0.6566\n","Epoch 4:\n","train Loss: 0.044 Acc: 1.0000\n","val Loss: 0.653 Acc: 0.6566\n","Epoch 5:\n","train Loss: 0.123 Acc: 0.9750\n","val Loss: 0.647 Acc: 0.6513\n","Epoch 6:\n","train Loss: 0.744 Acc: 0.7000\n","val Loss: 0.657 Acc: 0.6461\n","Epoch 7:\n","train Loss: 0.188 Acc: 0.9750\n","val Loss: 0.654 Acc: 0.6566\n","Epoch 8:\n","train Loss: 0.099 Acc: 1.0000\n","val Loss: 0.652 Acc: 0.6566\n","Epoch 9:\n","train Loss: 0.082 Acc: 1.0000\n","val Loss: 0.656 Acc: 0.6566\n","Epoch 10:\n","train Loss: 0.145 Acc: 0.9750\n","val Loss: 0.662 Acc: 0.6566\n","Epoch 11:\n","train Loss: 0.200 Acc: 0.9750\n","val Loss: 0.661 Acc: 0.6618\n","Epoch 12:\n","train Loss: 0.207 Acc: 1.0000\n","val Loss: 0.666 Acc: 0.6408\n","Epoch 13:\n","train Loss: 0.261 Acc: 1.0000\n","val Loss: 0.661 Acc: 0.6461\n","Epoch 14:\n","train Loss: 0.278 Acc: 0.9750\n","val Loss: 0.676 Acc: 0.6566\n","Epoch 15:\n","train Loss: 0.383 Acc: 0.9250\n","val Loss: 0.678 Acc: 0.6513\n","Epoch 16:\n","train Loss: 0.593 Acc: 0.6500\n","val Loss: 0.679 Acc: 0.6513\n","Epoch 17:\n","train Loss: 0.463 Acc: 0.9500\n","val Loss: 0.682 Acc: 0.6513\n","Epoch 18:\n","train Loss: 0.427 Acc: 1.0000\n","val Loss: 0.689 Acc: 0.6618\n","Epoch 19:\n","train Loss: 0.489 Acc: 0.8500\n","val Loss: 0.699 Acc: 0.3434\n","Epoch 20:\n","train Loss: 0.623 Acc: 0.6750\n","val Loss: 0.696 Acc: 0.3487\n","Epoch 21:\n","train Loss: 0.644 Acc: 0.6500\n","val Loss: 0.694 Acc: 0.3382\n","Epoch 22:\n","train Loss: 0.633 Acc: 0.7500\n","val Loss: 0.694 Acc: 0.3539\n","Epoch 23:\n","train Loss: 0.638 Acc: 0.7500\n","val Loss: 0.697 Acc: 0.3539\n","Epoch 24:\n","train Loss: 0.636 Acc: 0.7750\n","val Loss: 0.696 Acc: 0.3592\n","Epoch 25:\n","train Loss: 0.646 Acc: 0.8000\n","val Loss: 0.692 Acc: 0.6618\n","Parameters set 23/24\n","(0.1, 0, 0.01, 1, False, 15)\n","Epoch 0:\n","train Loss: 1.519 Acc: 0.4750\n","val Loss: 1.169 Acc: 0.6566\n","Epoch 1:\n","train Loss: 13.720 Acc: 0.3500\n","val Loss: 0.701 Acc: 0.6566\n","Epoch 2:\n","train Loss: 3.412 Acc: 0.5750\n","val Loss: 0.707 Acc: 0.6566\n","Epoch 3:\n","train Loss: 0.910 Acc: 0.6500\n","val Loss: 0.652 Acc: 0.6566\n","Epoch 4:\n","train Loss: 1.797 Acc: 0.5250\n","val Loss: 0.648 Acc: 0.6566\n","Epoch 5:\n","train Loss: 0.538 Acc: 0.8750\n","val Loss: 0.650 Acc: 0.6513\n","Epoch 6:\n","train Loss: 0.359 Acc: 0.9500\n","val Loss: 0.649 Acc: 0.6566\n","Epoch 7:\n","train Loss: 0.363 Acc: 0.9500\n","val Loss: 0.652 Acc: 0.6566\n","Epoch 8:\n","train Loss: 0.395 Acc: 0.8750\n","val Loss: 0.655 Acc: 0.6566\n","Epoch 9:\n","train Loss: 0.334 Acc: 0.9750\n","val Loss: 0.657 Acc: 0.6566\n","Epoch 10:\n","train Loss: 0.298 Acc: 0.9250\n","val Loss: 0.664 Acc: 0.6566\n","Epoch 11:\n","train Loss: 0.396 Acc: 0.8500\n","val Loss: 0.659 Acc: 0.6566\n","Epoch 12:\n","train Loss: 0.487 Acc: 0.8250\n","val Loss: 0.678 Acc: 0.6618\n","Epoch 13:\n","train Loss: 0.535 Acc: 0.6750\n","val Loss: 0.672 Acc: 0.6513\n","Epoch 14:\n","train Loss: 0.533 Acc: 0.6750\n","val Loss: 0.703 Acc: 0.3487\n","Epoch 15:\n","train Loss: 0.619 Acc: 0.6000\n","val Loss: 0.703 Acc: 0.3434\n","Epoch 16:\n","train Loss: 0.612 Acc: 0.7750\n","val Loss: 0.695 Acc: 0.3434\n","Epoch 17:\n","train Loss: 0.617 Acc: 0.9750\n","val Loss: 0.693 Acc: 0.6566\n","Epoch 18:\n","train Loss: 0.630 Acc: 0.9500\n","val Loss: 0.693 Acc: 0.6566\n","Epoch 19:\n","train Loss: 0.636 Acc: 0.9750\n","val Loss: 0.693 Acc: 0.6566\n","Epoch 20:\n","train Loss: 0.642 Acc: 0.9750\n","val Loss: 0.693 Acc: 0.3434\n","Epoch 21:\n","train Loss: 0.646 Acc: 0.9500\n","val Loss: 0.694 Acc: 0.3382\n","Epoch 22:\n","train Loss: 0.652 Acc: 0.8250\n","val Loss: 0.694 Acc: 0.3434\n","Epoch 23:\n","train Loss: 0.645 Acc: 0.9750\n","val Loss: 0.694 Acc: 0.3382\n","Epoch 24:\n","train Loss: 0.646 Acc: 0.9750\n","val Loss: 0.694 Acc: 0.3487\n","Epoch 25:\n","train Loss: 0.652 Acc: 0.8750\n","val Loss: 0.693 Acc: 0.3618\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SojjcIdQp8Ty","colab_type":"code","colab":{}},"source":["import copy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"m99ZpRmnFYN4","colab_type":"code","colab":{}},"source":["model = copy.deepcopy(model_cv.best_model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3nzoqgAO_OQz","colab_type":"code","colab":{}},"source":["torch.save(model, 'densenet_un')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QpLMQiM6pbRC","colab_type":"code","outputId":"a5be6a8d-5ecf-4335-e6fb-a8e9d59e5f07","executionInfo":{"status":"ok","timestamp":1567908816168,"user_tz":-180,"elapsed":1388,"user":{"displayName":"Владимир Чернявский","photoUrl":"","userId":"13952990532110748403"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["model_cv.best_acc"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9789473712444305"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"Hr5VQL0CYIks","colab_type":"code","colab":{}},"source":["\n","optimizer = torch.optim.SGD(model.parameters(), lr=8e-3, momentum=0.9, dampening=0, weight_decay=0.05)\n","# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=12, gamma=0.3)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNm3bqEN8O8G","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"ajvleeC2FYOA","colab_type":"code","colab":{}},"source":["model, best_model, val_acc = train_model(model, loss, optimizer, scheduler, n_epochs=100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"NzRdqF7GFYOH","colab_type":"code","outputId":"242e00f7-08e4-4c7c-e49c-0678ca206795","executionInfo":{"status":"error","timestamp":1567908822566,"user_tz":-180,"elapsed":1398,"user":{"displayName":"Владимир Чернявский","photoUrl":"","userId":"13952990532110748403"}},"colab":{"base_uri":"https://localhost:8080/","height":337}},"source":["test_dir = 'test'\n","shutil.copytree(os.path.join(data_root, 'test'),\n","               os.path.join(test_dir, 'unknown'))"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileExistsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-9afb9fbac4d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m shutil.copytree(os.path.join(data_root, 'test'),\n\u001b[0;32m----> 3\u001b[0;31m                os.path.join(test_dir, 'unknown'))\n\u001b[0m","\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mignored_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'test/unknown'"]}]},{"cell_type":"code","metadata":{"trusted":true,"id":"15L5JKGYFYOO","colab_type":"code","colab":{}},"source":["class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n","    def __getitem__(self, index):\n","        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n","        path = self.imgs[index][0]\n","        tuple_with_path = (original_tuple + (path, ))\n","        return tuple_with_path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"YTBiMJMxFYOU","colab_type":"code","colab":{}},"source":["test_dataset = ImageFolderWithPaths(test_dir, val_transforms)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"SSSwk35LFYOa","colab_type":"code","colab":{}},"source":["def evaluate(model, loader): \n","    model.eval()\n","\n","    test_predictions = []\n","    test_img_paths = []\n","    for inputs, _, paths in loader:\n","        inputs = inputs.to(device)\n","        with torch.set_grad_enabled(False):\n","            preds = model(inputs)\n","        test_predictions.append(torch.nn.functional.softmax(preds, dim=1)[:, 1].data.cpu().numpy())\n","        test_img_paths.extend(paths)\n","\n","    test_predictions = np.concatenate(test_predictions)\n","    return test_predictions, test_img_paths"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yVaY_xBFI890","colab_type":"code","colab":{}},"source":["test_predictions, test_img_paths = evaluate(model, test_loader)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"Yc4i2Qa9FYOf","colab_type":"code","outputId":"2dc7662a-dffb-4e07-99f1-e212dbdb096c","executionInfo":{"status":"ok","timestamp":1567908884869,"user_tz":-180,"elapsed":1360,"user":{"displayName":"Владимир Чернявский","photoUrl":"","userId":"13952990532110748403"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(test_predictions)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["744"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"trusted":true,"id":"Ry03Ty1UFYOl","colab_type":"code","outputId":"52cb2162-099b-4c73-8131-ccbaf66de9f9","executionInfo":{"status":"ok","timestamp":1567908886297,"user_tz":-180,"elapsed":892,"user":{"displayName":"Владимир Чернявский","photoUrl":"","userId":"13952990532110748403"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(test_img_paths)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["744"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"trusted":true,"id":"cWkiIvx1FYOx","colab_type":"code","colab":{}},"source":["submission_df = pd.DataFrame.from_dict({'id': test_img_paths,\n","                                        'label': test_predictions})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"gIwwTL5NFYO3","colab_type":"code","colab":{}},"source":["submission_df['label'] = submission_df['label'].map(lambda pred: 'dirty'\n","                                                   if pred > 0.5 else 'cleaned')\n","submission_df['id'] = submission_df['id'].str.replace('test/unknown/', '')\n","submission_df['id'] = submission_df['id'].str.replace('.jpg', '')\n","submission_df.set_index('id', inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"nBLTA8AFFYPA","colab_type":"code","outputId":"f4f49cda-eeb4-4dba-ad82-6e5dbbaba04b","executionInfo":{"status":"ok","timestamp":1567908899129,"user_tz":-180,"elapsed":1369,"user":{"displayName":"Владимир Чернявский","photoUrl":"","userId":"13952990532110748403"}},"colab":{"base_uri":"https://localhost:8080/","height":254}},"source":["submission_df.head(6)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0000</th>\n","      <td>dirty</td>\n","    </tr>\n","    <tr>\n","      <th>0001</th>\n","      <td>dirty</td>\n","    </tr>\n","    <tr>\n","      <th>0002</th>\n","      <td>dirty</td>\n","    </tr>\n","    <tr>\n","      <th>0003</th>\n","      <td>dirty</td>\n","    </tr>\n","    <tr>\n","      <th>0004</th>\n","      <td>dirty</td>\n","    </tr>\n","    <tr>\n","      <th>0005</th>\n","      <td>dirty</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      label\n","id         \n","0000  dirty\n","0001  dirty\n","0002  dirty\n","0003  dirty\n","0004  dirty\n","0005  dirty"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"trusted":true,"id":"SCiIKYB-FYPN","colab_type":"code","colab":{}},"source":["submission_df.to_csv('submission.csv')"],"execution_count":0,"outputs":[]}]}