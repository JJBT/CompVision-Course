{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir('../input'))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_root = '../input/plates/plates/'\nprint(os.listdir(data_root))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil \nfrom tqdm import tqdm\n\ntrain_dir = 'train'\nval_dir = 'val'\n\nclass_names = ['cleaned', 'dirty']\n\n# Создаем папки для тренировки и валидации\nfor dir_name in [train_dir, val_dir]:\n    for class_name in class_names:\n        os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n        \n# Каждый шестой сэмпл в валидацию\nfor class_name in class_names:\n    source_dir = os.path.join(data_root, 'train', class_name)\n    for i, filename in enumerate(tqdm(os.listdir(source_dir))):\n        if i % 6 != 0:\n            dest_dir = os.path.join(train_dir, class_name)\n        else:\n            dest_dir = os.path.join(val_dir, class_name)\n        shutil.copy(os.path.join(source_dir, filename), os.path.join(dest_dir, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport matplotlib.pyplot as plt\nimport time\nimport copy\nfrom torchvision import transforms, models\n\nshift_const = [0.485, 0.456, 0.406]\nscale_const = [0.229, 0.224, 0.225]\n\ntrain_transforms = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(shift_const, scale_const)\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(shift_const, scale_const)\n])\n\ntrain_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\nval_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n\nbatch_size = 8\n\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\nval_loader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_loader), len(train_dataset))\nprint(len(val_loader), len(val_dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_batch, y_batch = next(iter(train_loader))\nplt.imshow(X_batch[0].permute(1, 2, 0).numpy()*scale_const + shift_const);\nprint(y_batch[0].item())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_input(input_tensor, title=''):\n    image = input_tensor.permute(1, 2, 0).numpy() * scale_const + shift_const\n    plt.imshow(image.clip(0, 1))\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_batch, y_batch = next(iter(train_loader))\n\nfor x_item, y_item in zip(X_batch, y_batch):\n    show_input(x_item, title=class_names[y_item])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnet18(pretrained=True)\n\nfor param in model.parameters():\n    param.requires_grad = False\n    \nmodel.fc = torch.nn.Linear(model.fc.in_features, 2)\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=1.0e-3)\n\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, loss, optimizer, scheduler, n_epochs):\n    for epoch in range(n_epochs):\n        print('Epoch {}:'.format(epoch))\n        \n        for phase in ['train', 'val']:\n            if phase == 'train':\n                dataloader = train_loader\n#                 scheduler.step()\n                model.train()\n            else:\n                dataloader = val_loader\n                model.eval()\n                \n            batch_loss = 0.\n            batch_acc = 0.\n            \n            for inputs, labels in dataloader:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'):\n                    preds = model(inputs)\n                    loss_val = loss(preds, labels)\n                    preds_class = preds.argmax(dim=1)\n                    \n                    if phase == 'train':\n                        loss_val.backward()\n                        optimizer.step()\n                        scheduler.step()\n                        \n                batch_loss += loss_val.item()\n                batch_acc += (preds_class == labels.data).float().mean()\n                \n            epoch_loss = batch_loss / len(dataloader)\n            epoch_acc = batch_acc / len(dataloader)\n        \n            print('{} Loss: {:.3f} Acc: {:.3f}'.format(phase, epoch_loss, epoch_acc))\n    return model            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(model, loss, optimizer, scheduler, n_epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = 'test'\nshutil.copytree(os.path.join(data_root, 'test'),\n               os.path.join(test_dir, 'unknown'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n    def __getitem__(self, index):\n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        path = self.imgs[index][0]\n        tuple_with_path = (original_tuple + (path, ))\n        return tuple_with_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = ImageFolderWithPaths(test_dir, val_transforms)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n                                         shuffle=False, num_workers=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\n\ntest_predictions = []\ntest_img_paths = []\nfor inputs, _, paths in test_loader:\n    inputs = inputs.to(device)\n    with torch.set_grad_enabled(False):\n        preds = model(inputs)\n    test_predictions.append(torch.nn.functional.softmax(preds, dim=1)[:, 1].data.cpu().numpy())\n    test_img_paths.extend(paths)\n\ntest_predictions = np.concatenate(test_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img_paths","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs, labels, paths = next(iter(test_loader))\n\nfor img, pred in zip(inputs, test_predictions):\n    show_input(img, title=pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame.from_dict({'id': test_img_paths,\n                                        'label': test_predictions})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['label'] = submission_df['label'].map(lambda pred: 'dirty'\n                                                   if pred > 0.5 else 'cleaned')\nsubmission_df['id'] = submission_df['id'].str.replace('test/unknown/', '')\nsubmission_df['id'] = submission_df['id'].str.replace('.jpg', '')\nsubmission_df.set_index('id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf train val test","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}